"""
=============================================================================
EDRãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°çµ±åˆç‰ˆ v5.0 (JAX + CUDA)
Miosync, Inc. / Inverse-EDR Neural Calibration Engine (IENCE)

ã€æ¦‚è¦ã€‘
æ¿ææˆå½¢ã«ãŠã‘ã‚‹ç ´å£Šäºˆæ¸¬ã®ãŸã‚ã®çµ±ä¸€ç†è«–ï¼ˆEDRç†è«–ï¼‰å®Ÿè£…
- JAXç‰ˆï¼šãƒ¡ã‚¤ãƒ³å®Ÿè£…ï¼ˆCPU/GPUä¸¡å¯¾å¿œã€è‡ªå‹•å¾®åˆ†å¯èƒ½ï¼‰
- CUDAç‰ˆï¼šå¤§é‡ä¸¦åˆ—è©•ä¾¡ç”¨ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

ã€æœ€é©åŒ–æˆ¦ç•¥ã€‘
3ãƒ•ã‚§ãƒ¼ã‚ºHybridæœ€é©åŒ–ï¼š
  Phase 1: JAX + AdamWï¼ˆå¤§åŸŸæ¢ç´¢ã€2000ã‚¹ãƒ†ãƒƒãƒ—ï¼‰
  Phase 2: L-BFGS-Bï¼ˆå±€æ‰€ç²¾å¯†åŒ–ã€100ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
  Phase 3: AdamWï¼ˆå¾®èª¿æ•´ã€300ã‚¹ãƒ†ãƒƒãƒ—ï¼‰

ã€è‘—è€…ã€‘
é£¯æ³‰ çœŸé“ (Masamichi Iizumi)
ç’° (Tamaki) - AI Co-Developer

ã€æ—¥ä»˜ã€‘
2025-01-19
=============================================================================
"""

import numpy as np
import matplotlib.pyplot as plt
from dataclasses import dataclass
from typing import Callable, List, Dict, Tuple, Optional
from scipy.optimize import minimize, Bounds, differential_evolution
from scipy.signal import savgol_filter
from collections import deque
import time

# JAXé–¢é€£ï¼ˆå¿…é ˆï¼‰
try:
    import jax
    import jax.numpy as jnp
    from jax import jit, vmap, grad
    import optax
    JAX_AVAILABLE = True
    print(f"âœ“ JAXåˆ©ç”¨å¯èƒ½: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ {jax.__version__}")
except ImportError:
    raise ImportError("JAXãŒå¿…è¦ã§ã™: pip install jax jaxlib")

# CUDAé–¢é€£ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
CUDA_AVAILABLE = False
try:
    from numba import cuda, float64, int32
    import math
    CUDA_AVAILABLE = cuda.is_available()
    if CUDA_AVAILABLE:
        print(f"âœ“ CUDAåˆ©ç”¨å¯èƒ½: {cuda.get_current_device().name.decode()}")
    else:
        print("âš ï¸  CUDAç„¡åŠ¹: JAX modeã§å®Ÿè¡Œ")
except ImportError:
    print("âš ï¸  Numbaæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: JAX modeã®ã¿")

# =============================================================================
# Section 1: ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
# =============================================================================

@dataclass
class MaterialParams:
    """ææ–™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"""
    rho: float = 7800.0      # å¯†åº¦ [kg/m3]
    cp: float = 500.0        # æ¯”ç†± [J/kg/K]
    k: float = 40.0          # ç†±ä¼å°ç‡ [W/m/K]
    thickness: float = 0.0008 # æ¿åš [m]
    sigma0: float = 600e6    # åˆæœŸé™ä¼å¿œåŠ› [Pa]
    n: float = 0.15          # åŠ å·¥ç¡¬åŒ–æŒ‡æ•°
    m: float = 0.02          # é€Ÿåº¦æ„Ÿå—æŒ‡æ•°
    r_value: float = 1.0     # ãƒ©ãƒ³ã‚¯ãƒ•ã‚©ãƒ¼ãƒ‰å€¤

@dataclass
class EDRParams:
    """EDRç†è«–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"""
    V0: float = 2e9            # åŸºæº–å‡é›†ã‚¨ãƒãƒ«ã‚®ãƒ¼ [Pa = J/m3]
    av: float = 3e4            # ç©ºå­”å½±éŸ¿ä¿‚æ•°
    ad: float = 1e-7           # è»¢ä½å½±éŸ¿ä¿‚æ•°
    chi: float = 0.1           # æ‘©æ“¦ç™ºç†±ã®å†…éƒ¨åˆ†é…ç‡
    K_scale: float = 0.2       # Kç·é‡ã‚¹ã‚±ãƒ¼ãƒ«
    triax_sens: float = 0.3    # ä¸‰è»¸åº¦æ„Ÿåº¦
    Lambda_crit: float = 1.0   # è‡¨ç•ŒÎ›
    # çµŒè·¯åˆ¥ã‚¹ã‚±ãƒ¼ãƒ«ä¿‚æ•°
    K_scale_draw: float = 0.15   # æ·±çµã‚Šç”¨
    K_scale_plane: float = 0.25  # å¹³é¢ã²ãšã¿ç”¨
    K_scale_biax: float = 0.20   # ç­‰äºŒè»¸ç”¨
    # FLC Vå­—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    beta_A: float = 0.35       # è°·ã®æ·±ã•
    beta_bw: float = 0.28      # è°·ã®å¹…
    # éå¯¾ç§°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    beta_A_pos: float = 0.50   # ç­‰äºŒè»¸å´ã®æ·±ã•

@dataclass
class PressSchedule:
    """FEM or å®Ÿé¨“ãƒ­ã‚°ã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿"""
    t: np.ndarray                 # æ™‚é–“ [s]
    eps_maj: np.ndarray           # ä¸»ã²ãšã¿
    eps_min: np.ndarray           # å‰¯ã²ãšã¿
    triax: np.ndarray             # ä¸‰è»¸åº¦ Ïƒm/Ïƒeq
    mu: np.ndarray                # æ‘©æ“¦ä¿‚æ•°
    pN: np.ndarray                # æ¥è§¦åœ§ [Pa]
    vslip: np.ndarray             # ã™ã¹ã‚Šé€Ÿåº¦ [m/s]
    htc: np.ndarray               # ç†±ä¼é”ä¿‚æ•° [W/m2/K]
    Tdie: np.ndarray              # é‡‘å‹æ¸©åº¦ [K]
    contact: np.ndarray           # æ¥è§¦ç‡ [0-1]
    T0: float = 293.15            # æ¿ã®åˆæœŸæ¸©åº¦ [K]

@dataclass
class ExpBinary:
    """ç ´æ–­/å®‰å…¨ã®ãƒ©ãƒ™ãƒ«ä»˜ãå®Ÿé¨“"""
    schedule: PressSchedule
    failed: int                   # 1:ç ´æ–­, 0:å®‰å…¨
    label: str = ""

@dataclass
class FLCPoint:
    """FLC: çµŒè·¯æ¯”ä¸€å®šã§ã®é™ç•Œç‚¹ï¼ˆå®Ÿæ¸¬ï¼‰"""
    path_ratio: float            # Î² = eps_min/eps_maj
    major_limit: float           # å®Ÿæ¸¬é™ç•Œä¸»ã²ãšã¿
    minor_limit: float           # å®Ÿæ¸¬é™ç•Œå‰¯ã²ãšã¿
    rate_major: float = 1.0      # ä¸»ã²ãšã¿é€Ÿåº¦ [1/s]
    duration_max: float = 1.0    # è©¦é¨“ä¸Šé™æ™‚é–“ [s]
    label: str = ""

# =============================================================================
# Section 2: JAXãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# =============================================================================

def schedule_to_jax_dict(schedule: PressSchedule):
    """PressSchedule â†’ JAXç”¨dictå¤‰æ›"""
    return {
        't': jnp.array(schedule.t),
        'eps_maj': jnp.array(schedule.eps_maj),
        'eps_min': jnp.array(schedule.eps_min),
        'triax': jnp.array(schedule.triax),
        'mu': jnp.array(schedule.mu),
        'pN': jnp.array(schedule.pN),
        'vslip': jnp.array(schedule.vslip),
        'htc': jnp.array(schedule.htc),
        'Tdie': jnp.array(schedule.Tdie),
        'contact': jnp.array(schedule.contact),
        'T0': schedule.T0
    }

def mat_to_jax_dict(mat: MaterialParams):
    """MaterialParams â†’ JAXç”¨dictå¤‰æ›"""
    return {
        'rho': mat.rho,
        'cp': mat.cp,
        'h0': mat.thickness,
        'sigma0': mat.sigma0,
        'n': mat.n,
        'm': mat.m,
        'r_value': mat.r_value
    }

@jit
def soft_clamp(x, min_val, max_val):
    """ã‚½ãƒ•ãƒˆå¢ƒç•Œåˆ¶ç´„ï¼ˆå¾®åˆ†å¯èƒ½ï¼‰"""
    return min_val + (max_val - min_val) * jax.nn.sigmoid(x)

@jit
def triax_from_path_jax(beta):
    """ã²ãšã¿çµŒè·¯æ¯”Î²ã‹ã‚‰ä¸‰è»¸åº¦Î·ã‚’è¨ˆç®—"""
    b = jnp.clip(beta, -0.95, 1.0)
    return (1.0 + b) / (jnp.sqrt(3.0) * jnp.sqrt(1.0 + b + b*b))

@jit
def equiv_strain_rate_jax(epsM_dot, epsm_dot):
    """ç›¸å½“ã²ãšã¿é€Ÿåº¦"""
    sqrt_2_3 = 0.8164965809277260
    return sqrt_2_3 * jnp.sqrt(
        (epsM_dot - epsm_dot)**2 + epsM_dot**2 + epsm_dot**2
    )

@jit
def flow_stress_jax(ep_eq, epdot_eq, sigma0, n, m, r_value, T):
    """æ¸©åº¦ä¾å­˜ã®æµå‹•å¿œåŠ›"""
    Tref = 293.15
    alpha = 3e-4
    rate_fac = jnp.power(jnp.maximum(epdot_eq, 1e-6), m)
    aniso = (2.0 + r_value) / 3.0
    temp_fac = 1.0 - alpha * jnp.maximum(T - Tref, 0.0)
    return sigma0 * temp_fac * jnp.power(1.0 + ep_eq, n) * rate_fac / aniso

@jit
def step_cv_jax(cv, T, rho_d, dt):
    """ç©ºå­”æ¿ƒåº¦ã®æ™‚é–“ç™ºå±•"""
    kB_eV = 8.617e-5
    c0 = 1e-6; Ev_eV = 1.0; tau0 = 1e-3; Q_eV = 0.8
    k_ann = 1e6; k_sink = 1e-15
    
    cv_eq = c0 * jnp.exp(-Ev_eV / (kB_eV * T))
    tau = tau0 * jnp.exp(Q_eV / (kB_eV * T))
    dcv = (cv_eq - cv) / tau - k_ann * cv**2 - k_sink * cv * rho_d
    return cv + dcv * dt

@jit
def step_rho_jax(rho_d, epdot_eq, T, dt):
    """è»¢ä½å¯†åº¦ã®æ™‚é–“ç™ºå±•"""
    A = 1e14; B = 1e-4; Qv_eV = 0.8; kB_eV = 8.617e-5
    Dv = 1e-6 * jnp.exp(-Qv_eV / (kB_eV * T))
    drho = A * jnp.maximum(epdot_eq, 0.0) - B * rho_d * Dv
    return jnp.maximum(rho_d + drho * dt, 1e10)

@jit
def get_k_scale_smooth_jax(beta, params):
    """æ»‘ã‚‰ã‹ãªK_scaleé¸æŠï¼ˆåˆ†å²ãƒ¬ã‚¹ï¼‰"""
    w_draw = jnp.exp(-((beta + 0.5) / 0.1)**2)
    w_plane = jnp.exp(-(beta / 0.1)**2)
    w_biax = jnp.exp(-((beta - 0.5) / 0.2)**2)
    w_else = 1.0 - jnp.maximum(w_draw, jnp.maximum(w_plane, w_biax))
    
    w_sum = w_draw + w_plane + w_biax + w_else + 1e-8
    
    return (params["K_scale_draw"] * w_draw + 
            params["K_scale_plane"] * w_plane +
            params["K_scale_biax"] * w_biax +
            params["K_scale"] * w_else) / w_sum

@jit
def beta_multiplier_jax(beta, A, bw):
    """Î²ä¾å­˜ã‚²ã‚¤ãƒ³ï¼ˆVå­—å½¢çŠ¶ï¼‰"""
    b = jnp.clip(beta, -0.95, 0.95)
    return 1.0 + A * jnp.exp(-(b / bw)**2)

@jit
def beta_multiplier_asymmetric_jax(beta, A_neg, A_pos, bw):
    """éå¯¾ç§°Î²ä¾å­˜ã‚²ã‚¤ãƒ³"""
    b = jnp.clip(beta, -0.95, 0.95)
    A = jnp.where(b < 0, A_neg, A_pos)
    return 1.0 + A * jnp.exp(-(b / bw)**2)

@jit
def mu_effective_jax(mu0, T, pN, vslip):
    """æ¸©åº¦ãƒ»é€Ÿåº¦ãƒ»è·é‡ä¾å­˜ã®æœ‰åŠ¹æ‘©æ“¦ä¿‚æ•°ï¼ˆStribecké¢¨ï¼‰"""
    s = (vslip * 1e3) / (pN / 1e6 + 1.0)
    stribeck = 0.7 + 0.3 / (1 + s)
    temp_reduction = 1.0 - 1e-4 * jnp.maximum(T - 293.15, 0)
    return mu0 * stribeck * temp_reduction

def smooth_signal_jax(x, window_size=11):
    """JAXç‰ˆç§»å‹•å¹³å‡ã«ã‚ˆã‚‹ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆã‚¹ãƒ‘ã‚¤ã‚¯é™¤å»ï¼‰"""
    if window_size <= 1 or len(x) <= window_size:
        return x
    kernel = jnp.ones(window_size) / window_size
    # JAXç‰ˆã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã¨ç•³ã¿è¾¼ã¿
    padded = jnp.pad(x, (window_size//2, window_size//2), mode='edge')
    smoothed = jnp.convolve(padded, kernel, mode='valid')
    return smoothed[:len(x)]

def sanity_check_jax(schedule_dict):
    """å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆJAXç‰ˆï¼‰"""
    pN = schedule_dict['pN']
    Tdie = schedule_dict['Tdie']
    t = schedule_dict['t']
    contact = schedule_dict['contact']
    mu = schedule_dict['mu']
    
    checks = [
        jnp.all(pN < 5e9),  # pN too large?
        jnp.all(pN > 0),    # pN must be positive
        jnp.all(Tdie > 150),  # Tdie out of range?
        jnp.all(Tdie < 1500),
        jnp.all(t >= 0),    # Time must be non-negative
        jnp.all(contact >= 0),  # Contact rate in [0,1]
        jnp.all(contact <= 1),
        jnp.all(mu >= 0),   # Friction coefficient
        jnp.all(mu < 1),
    ]
    
    return jnp.all(jnp.array(checks))

# =============================================================================
# Section 3: ãƒ¡ã‚¤ãƒ³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆJAXç‰ˆï¼‰
# =============================================================================

@jit
def simulate_lambda_jax(schedule_dict, mat_dict, edr_dict):
    """JAXç‰ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒ¡ã‚¤ãƒ³å®Ÿè£…ï¼‰"""
    
    # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
    # sanity_check_jax(schedule_dict)  # JITå†…ã§ã¯çœç•¥
    
    # ãƒ‡ãƒ¼ã‚¿å–ã‚Šå‡ºã—
    t = schedule_dict['t']
    epsM = schedule_dict['eps_maj']
    epsm = schedule_dict['eps_min']
    triax = schedule_dict['triax']
    mu = schedule_dict['mu']
    pN = schedule_dict['pN']
    vslip = schedule_dict['vslip']
    htc = schedule_dict['htc']
    Tdie = schedule_dict['Tdie']
    contact = schedule_dict['contact']
    T0 = schedule_dict['T0']
    
    dt = (t[-1] - t[0]) / (len(t) - 1)
    
    # ã²ãšã¿é€Ÿåº¦è¨ˆç®—
    epsM_dot = jnp.gradient(epsM, dt)
    epsm_dot = jnp.gradient(epsm, dt)
    
    # çµŒè·¯å¹³å‡Î²
    beta_avg = jnp.mean(epsm / (epsM + 1e-10))
    
    # scanã§æ™‚é–“ãƒ«ãƒ¼ãƒ—
    def time_step(carry, inputs):
        T, cv, rho_d, ep_eq, h_eff, eps3, beta_hist = carry
        idx = inputs
        
        epsM_dot_t = epsM_dot[idx]
        epsm_dot_t = epsm_dot[idx]
        triax_t = triax[idx]
        mu_t = mu[idx]
        pN_t = pN[idx]
        vslip_t = vslip[idx]
        htc_t = htc[idx]
        Tdie_t = Tdie[idx]
        contact_t = contact[idx]
        
        # ç›¸å½“ã²ãšã¿é€Ÿåº¦
        epdot_eq = equiv_strain_rate_jax(epsM_dot_t, epsm_dot_t)
        
        # æ¿åšæ›´æ–°
        d_eps3 = -(epsM_dot_t + epsm_dot_t) * dt
        eps3_new = eps3 + d_eps3
        h_eff_new = jnp.maximum(mat_dict['h0'] * jnp.exp(eps3_new), 0.2 * mat_dict['h0'])
        
        # ç†±åæ”¯
        q_fric = mu_t * pN_t * vslip_t * contact_t
        dTdt = (2.0 * htc_t * (Tdie_t - T) + 2.0 * edr_dict['chi'] * q_fric) / \
               (mat_dict['rho'] * mat_dict['cp'] * h_eff_new)
        dTdt = jnp.clip(dTdt, -1000.0, 1000.0)
        T_new = jnp.clip(T + dTdt * dt, 200.0, 2000.0)
        
        # æ¬ é™¥æ›´æ–°
        rho_d_new = step_rho_jax(rho_d, epdot_eq, T, dt)
        cv_new = step_cv_jax(cv, T, rho_d_new, dt)
        
        # Kè¨ˆç®—ï¼ˆæ”¹å–„ç‰ˆï¼šå†·å´ã¯å›å¾©å´ï¼‰
        K_th = mat_dict['rho'] * mat_dict['cp'] * jnp.maximum(dTdt, 0.0)  # åŠ ç†±æ™‚ã®ã¿ã‚«ã‚¦ãƒ³ãƒˆï¼
        
        # æ¸©åº¦ä¾å­˜ã®æµå‹•å¿œåŠ›
        sigma_eq = flow_stress_jax(ep_eq, epdot_eq, mat_dict['sigma0'], 
                                   mat_dict['n'], mat_dict['m'], mat_dict['r_value'], T)
        K_pl = 0.9 * sigma_eq * epdot_eq
        
        # æ¸©åº¦ãƒ»é€Ÿåº¦ãƒ»è·é‡ä¾å­˜ã®æ‘©æ“¦ä¿‚æ•°ï¼ˆç‰©ç†å¢—å¼·ï¼‰
        mu_eff = mu_effective_jax(mu_t, T, pN_t, vslip_t)
        q_fric_eff = mu_eff * pN_t * vslip_t * contact_t
        K_fr = (2.0 * edr_dict['chi'] * q_fric_eff) / h_eff_new
        
        # K_scaleé¸æŠ
        k_scale_path = get_k_scale_smooth_jax(beta_avg, edr_dict)
        
        # Î²ç¬é–“å€¤ã¨Î²å±¥æ­´ã®5ç‚¹ç§»å‹•å¹³å‡
        beta_inst = epsm_dot_t / (epsM_dot_t + 1e-8)
        
        # Î²å±¥æ­´æ›´æ–°ï¼ˆ5ç‚¹ç§»å‹•å¹³å‡ï¼‰
        beta_hist_new = jnp.roll(beta_hist, -1).at[4].set(beta_inst)
        beta_smooth = jnp.mean(beta_hist_new)
        
        # K_totalï¼ˆéå¯¾ç§°ã‚²ã‚¤ãƒ³ä½¿ç”¨ï¼‰
        K_total = k_scale_path * (K_th + K_pl + K_fr)
        K_total *= beta_multiplier_asymmetric_jax(
            beta_smooth, 
            edr_dict['beta_A'], 
            edr_dict.get('beta_A_pos', edr_dict['beta_A']),
            edr_dict['beta_bw']
        )
        K_total = jnp.maximum(K_total, 0.0)
        K_total = jnp.where(jnp.isnan(K_total), 0.0, K_total)  # NaNå¯¾ç­–
        
        # V_effï¼ˆæ¸©åº¦ä¾å­˜æ€§ã‚’å¼·åŒ–ï¼‰
        T_ratio = jnp.minimum((T - 273.15) / (1500.0 - 273.15), 1.0)
        temp_factor = 1.0 - 0.5 * T_ratio  # æ¸©åº¦ãŒä¸ŠãŒã‚‹ã¨V_effãŒä¸‹ãŒã‚‹
        V_eff = edr_dict['V0'] * temp_factor * \
                (1.0 - edr_dict['av'] * cv - edr_dict['ad'] * jnp.sqrt(jnp.maximum(rho_d, 1e10)))
        V_eff = jnp.maximum(V_eff, 0.01 * edr_dict['V0'])
        V_eff = jnp.where(jnp.isnan(V_eff), edr_dict['V0'], V_eff)  # NaNå¯¾ç­–
        
        # ä¸‰è»¸åº¦è£œæ­£ï¼ˆæ„Ÿåº¦ã‚’èª¿æ•´ï¼‰
        D_triax = jnp.exp(-edr_dict['triax_sens'] * jnp.maximum(triax_t, 0.0))
        D_triax = jnp.where(jnp.isnan(D_triax), 1.0, D_triax)  # NaNå¯¾ç­–
        
        # Î›è¨ˆç®—
        Lambda = K_total / jnp.maximum(V_eff * D_triax, 1e7)
        Lambda = jnp.minimum(Lambda, 10.0)
        Lambda = jnp.where(jnp.isnan(Lambda), 0.0, Lambda)  # NaNå¯¾ç­–
        
        # ç›¸å½“å¡‘æ€§ã²ãšã¿æ›´æ–°
        ep_eq_new = ep_eq + epdot_eq * dt
        
        new_carry = (T_new, cv_new, rho_d_new, ep_eq_new, h_eff_new, eps3_new, beta_hist_new)
        return new_carry, Lambda
    
    # åˆæœŸçŠ¶æ…‹ï¼ˆÎ²å±¥æ­´ã‚‚åˆæœŸåŒ–ï¼‰
    init_beta_hist = jnp.zeros(5)  # 5ç‚¹ç§»å‹•å¹³å‡ç”¨
    init_carry = (T0, 1e-7, 1e11, 0.0, mat_dict['h0'], 0.0, init_beta_hist)
    
    # scanå®Ÿè¡Œ
    indices = jnp.arange(len(t) - 1)
    _, Lambdas = jax.lax.scan(time_step, init_carry, indices)
    
    # Damageç©åˆ†
    Damage = jnp.cumsum(jnp.maximum(Lambdas - edr_dict['Lambda_crit'], 0.0) * dt)
    
    return {"Lambda": Lambdas, "Damage": Damage}

# =============================================================================
# Section 4: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç®¡ç†ã¨æå¤±é–¢æ•°
# =============================================================================

def init_edr_params_jax():
    """JAXç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆæœŸåŒ–ï¼ˆãƒãƒ©ãƒ³ã‚¹èª¿æ•´ç‰ˆï¼‰"""
    return {
        'log_V0': jnp.log(1.5e9),    # 1e9â†’1.5e9
        'log_av': jnp.log(4e4),       # 5e4â†’4e4
        'log_ad': jnp.log(1e-7),      
        'logit_chi': jnp.log(0.09 / (1 - 0.09)),    
        'logit_K_scale': jnp.log(0.25 / (1 - 0.25)),  # 0.3â†’0.25
        'logit_K_scale_draw': jnp.log(0.18 / (1 - 0.18)),  # 0.2â†’0.18
        'logit_K_scale_plane': jnp.log(0.25 / (1 - 0.25)),
        'logit_K_scale_biax': jnp.log(0.22 / (1 - 0.22)),  # 0.25â†’0.22
        'logit_triax_sens': jnp.log(0.28 / (1 - 0.28)),   # 0.25â†’0.28
        'Lambda_crit': jnp.array(0.97),  # 0.95â†’0.97
        'logit_beta_A': jnp.log(0.32 / (1 - 0.32)),      # 0.3â†’0.32
        'logit_beta_bw': jnp.log(0.29 / (1 - 0.29)),     # 0.3â†’0.29
        'logit_beta_A_pos': jnp.log(0.48 / (1 - 0.48)),  # 0.45â†’0.48
    }

def transform_params_jax(raw_params):
    """åˆ¶ç´„ä»˜ããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤‰æ›ï¼ˆsoft boundsï¼‰"""
    return {
        'V0': jnp.exp(raw_params['log_V0']),
        'av': jnp.exp(raw_params['log_av']),
        'ad': jnp.exp(raw_params['log_ad']),
        'chi': soft_clamp(raw_params['logit_chi'], 0.05, 0.3),
        'K_scale': soft_clamp(raw_params['logit_K_scale'], 0.05, 1.0),
        'K_scale_draw': soft_clamp(raw_params['logit_K_scale_draw'], 0.05, 0.3),
        'K_scale_plane': soft_clamp(raw_params['logit_K_scale_plane'], 0.1, 0.4),
        'K_scale_biax': soft_clamp(raw_params['logit_K_scale_biax'], 0.05, 0.3),
        'triax_sens': soft_clamp(raw_params['logit_triax_sens'], 0.1, 0.5),
        'Lambda_crit': jnp.clip(raw_params['Lambda_crit'], 0.95, 1.05),
        'beta_A': soft_clamp(raw_params['logit_beta_A'], 0.2, 0.5),
        'beta_bw': soft_clamp(raw_params['logit_beta_bw'], 0.2, 0.35),
        'beta_A_pos': soft_clamp(raw_params['logit_beta_A_pos'], 0.3, 0.7),
    }

def edr_dict_to_dataclass(edr_dict):
    """dict â†’ EDRParamså¤‰æ›ï¼ˆJAXå€¤ã‚’å–å¾—ï¼‰"""
    return EDRParams(
        V0=float(jax.device_get(edr_dict['V0'])),
        av=float(jax.device_get(edr_dict['av'])),
        ad=float(jax.device_get(edr_dict['ad'])),
        chi=float(jax.device_get(edr_dict['chi'])),
        K_scale=float(jax.device_get(edr_dict['K_scale'])),
        triax_sens=float(jax.device_get(edr_dict['triax_sens'])),
        Lambda_crit=float(jax.device_get(edr_dict['Lambda_crit'])),
        K_scale_draw=float(jax.device_get(edr_dict['K_scale_draw'])),
        K_scale_plane=float(jax.device_get(edr_dict['K_scale_plane'])),
        K_scale_biax=float(jax.device_get(edr_dict['K_scale_biax'])),
        beta_A=float(jax.device_get(edr_dict['beta_A'])),
        beta_bw=float(jax.device_get(edr_dict['beta_bw'])),
        beta_A_pos=float(jax.device_get(edr_dict.get('beta_A_pos', edr_dict['beta_A']))),
    )

def loss_single_exp_jax(schedule_dict, mat_dict, edr_dict, failed):
    """å˜ä¸€å®Ÿé¨“ã®æå¤±ï¼ˆJAXç‰ˆï¼‰"""
    res = simulate_lambda_jax(schedule_dict, mat_dict, edr_dict)
    
    # ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã—ã¦ã‚¹ãƒ‘ã‚¤ã‚¯ã‚’é™¤å»ï¼ˆé‡è¦ï¼ï¼‰
    Lambda_smooth = smooth_signal_jax(res["Lambda"], window_size=11)
    
    peak = jnp.max(Lambda_smooth)
    D_end = res["Damage"][-1]
    
    margin = 0.08
    Dcrit = 0.01  # 0.05ã‹ã‚‰0.01ã«ç·©å’Œ
    delta = 0.03  # å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³
    
    # failed == 1ã®å ´åˆï¼ˆç ´æ–­ï¼‰
    condition_met = (peak > edr_dict['Lambda_crit']) & (D_end > Dcrit)
    
    peak_penalty = jnp.maximum(0.0, edr_dict['Lambda_crit'] - peak)
    D_penalty = jnp.maximum(0.0, Dcrit - D_end)
    loss_fail_not_met = 10.0 * (peak_penalty**2 + D_penalty**2)
    
    margin_loss = jnp.where(
        peak < edr_dict['Lambda_crit'] + margin,
        (edr_dict['Lambda_crit'] + margin - peak)**2,
        0.0
    )
    D_loss = jnp.where(
        D_end < 2*Dcrit,
        (2*Dcrit - D_end)**2,
        0.0
    )
    loss_fail_met = margin_loss + D_loss
    
    loss_fail = jnp.where(condition_met, loss_fail_met, loss_fail_not_met)
    
    # failed == 0ã®å ´åˆï¼ˆå®‰å…¨ï¼‰
    loss_safe_peak = jnp.where(
        peak > edr_dict['Lambda_crit'] - delta,
        (peak - (edr_dict['Lambda_crit'] - delta))**2 * 3.0,  # ä¿‚æ•°ã‚’å¢—ã‚„ã—ã¦é‡è¦è¦–
        0.0
    )
    loss_safe_D = jnp.where(
        D_end >= 0.5*Dcrit,
        10.0 * (D_end - 0.5*Dcrit)**2,
        0.0
    )
    loss_safe = loss_safe_peak + loss_safe_D
    
    return jnp.where(failed == 1, loss_fail, loss_safe)

def loss_fn_jax(raw_params, exps, mat):
    """ãƒãƒƒãƒæå¤±é–¢æ•°"""
    edr_dict = transform_params_jax(raw_params)
    
    # ãƒ‡ãƒ¼ã‚¿å¤‰æ›
    mat_dict = mat_to_jax_dict(mat)
    
    total_loss = 0.0
    for exp in exps:
        schedule_dict = schedule_to_jax_dict(exp.schedule)
        loss = loss_single_exp_jax(schedule_dict, mat_dict, edr_dict, exp.failed)
        total_loss += loss
    
    return total_loss / len(exps)

# =============================================================================
# Section 5: 3ãƒ•ã‚§ãƒ¼ã‚ºHybridæœ€é©åŒ–
# =============================================================================

def hybrid_staged_optimization(
    exps: List[ExpBinary],
    flc_pts: List[FLCPoint],
    mat: MaterialParams,
    initial_edr: Optional[EDRParams] = None,
    verbose: bool = True
) -> Tuple[EDRParams, Dict]:
    """
    å¤šæ®µéšHybridæœ€é©åŒ–
    Phase 0: Unsupervised FLC Pretrainingï¼ˆç‰©ç†åˆ¶ç´„ã®ã¿ï¼‰
    Phase 1: JAX + AdamWï¼ˆå¤§åŸŸæ¢ç´¢ï¼‰
    Phase 1.5: FLC Shapingï¼ˆÎ²æ–¹å‘ã®å½¢çŠ¶å­¦ç¿’ï¼‰
    Phase 2: L-BFGS-Bï¼ˆå±€æ‰€ç²¾å¯†åŒ–ï¼‰
    Phase 3: JAX + AdamWï¼ˆå¾®èª¿æ•´ï¼‰
    """
    
    if initial_edr is None:
        initial_edr = EDRParams()
    
    # å…±é€šã§ä½¿ç”¨ã™ã‚‹é–¢æ•°ã‚’å…ˆã«å®šç¾©
    mat_dict = mat_to_jax_dict(mat)
    
    # Phase 0ç”¨ã®å®‰å®šç‰ˆï¼ˆargmaxä½¿ç”¨ï¼‰
    def predict_flc_jax_stable(path_ratio, edr_dict, mat_dict):
        """Phase 0ç”¨ã®å®‰å®šç‰ˆFLCäºˆæ¸¬ï¼ˆargmaxä½¿ç”¨ï¼‰"""
        duration = 1.0
        major_rate = 0.6
        dt = 1e-3
        N = int(duration/dt) + 1
        t = jnp.linspace(0, duration, N)
        epsM = major_rate * t
        epsm = path_ratio * epsM
        
        schedule_dict = {
            't': t,
            'eps_maj': epsM,
            'eps_min': epsm,
            'triax': jnp.full(N, triax_from_path_jax(path_ratio)),
            'mu': jnp.full(N, 0.08),
            'pN': jnp.full(N, 200e6),
            'vslip': jnp.full(N, 0.02),
            'htc': jnp.full(N, 8000.0),
            'Tdie': jnp.full(N, 293.15),
            'contact': jnp.full(N, 1.0),
            'T0': 293.15
        }
        
        res = simulate_lambda_jax(schedule_dict, mat_dict, edr_dict)
        Lambda_smooth = smooth_signal_jax(res["Lambda"], window_size=11)
        
        # å®‰å®šç‰ˆï¼šargmaxä½¿ç”¨
        exceed_mask = Lambda_smooth > edr_dict['Lambda_crit']
        first_exceed = jnp.argmax(exceed_mask)
        has_exceeded = jnp.any(exceed_mask)
        
        epsM_trimmed = epsM[:-1]
        Em = jnp.where(has_exceeded, epsM_trimmed[first_exceed], epsM_trimmed[-1])
        em = path_ratio * Em
        
        return Em, em
    
    def soft_crossing_em(epsM, Lambda, Lambda_crit, k=10.0):  # 40â†’10ã«ä¸‹ã’ã‚‹
        """Î›>Î›critè¿‘å‚ã§é‡ã¿ä»˜ãå¹³å‡ä¸»ã²ãšã¿ã‚’è¿”ã™ï¼ˆå¾®åˆ†å¯èƒ½ï¼‰"""
        exceed = jnp.maximum(Lambda - Lambda_crit, 0.0)
        w = jnp.exp(jnp.minimum(k * exceed, 10.0))  # 20.0â†’10.0ã§ã‚ˆã‚Šå®‰å®š
        w = w / (jnp.sum(w) + 1e-12)
        Em = jnp.sum(w * epsM)
        Em = jnp.where(jnp.isnan(Em), epsM[-1], Em)  # NaNå¯¾ç­–
        return Em
    
    def predict_flc_from_sim_jax(beta, mat_dict, edr_dict, 
                                  major_rate=0.6, duration=1.0):
        """Î›(t)ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‹ã‚‰FLCé™ç•Œç‚¹ã‚’å¾®åˆ†å¯èƒ½ã«æŠ½å‡º"""
        dt = 1e-3
        N = int(duration/dt) + 1
        t = jnp.linspace(0, duration, N)
        epsM = major_rate * t
        epsm = beta * epsM
        
        schedule_dict = {
            't': t,
            'eps_maj': epsM,
            'eps_min': epsm,
            'triax': jnp.full(N, triax_from_path_jax(beta)),
            'mu': jnp.full(N, 0.08),
            'pN': jnp.full(N, 200e6),
            'vslip': jnp.full(N, 0.02),
            'htc': jnp.full(N, 8000.0),
            'Tdie': jnp.full(N, 293.15),
            'contact': jnp.full(N, 1.0),
            'T0': 293.15
        }
        
        res = simulate_lambda_jax(schedule_dict, mat_dict, edr_dict)
        Lambda_raw = res["Lambda"]  # é•·ã•ã¯N-1
        
        # ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
        Lambda_smooth = smooth_signal_jax(Lambda_raw, window_size=11)
        
        # epsMé…åˆ—ã‚’Lambdaã®é•·ã•ã«åˆã‚ã›ã‚‹ï¼ˆæœ€å¾Œã®è¦ç´ ã‚’é™¤ãï¼‰
        epsM_trimmed = epsM[:-1]
        
        # å¾®åˆ†å¯èƒ½ãªé™ç•Œç‚¹æ¤œå‡ºï¼ˆkå€¤ã‚’ä¸‹ã’ã¦å®‰å®šåŒ–ï¼‰
        Em = soft_crossing_em(epsM_trimmed, Lambda_smooth, edr_dict['Lambda_crit'], k=10.0)  # 40â†’10
        em = beta * Em
        
        return Em, em, Lambda_smooth
    
    # ç°¡æ˜“FLCäºˆæ¸¬ï¼ˆJAXç‰ˆï¼‰- äº’æ›æ€§ã®ãŸã‚æ®‹ã™
    def predict_flc_jax(path_ratio, edr_dict, mat_dict):
        """å®Ÿéš›ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹FLCäºˆæ¸¬ï¼ˆäº’æ›æ€§ç”¨ï¼‰"""
        Em, em, _ = predict_flc_from_sim_jax(path_ratio, mat_dict, edr_dict)
        return Em, em
    
    # ===========================
    # Phase 0: Unsupervised FLC Pretraining
    # ===========================
    if verbose:
        print("\n" + "="*60)
        print(" Phase 0: Unsupervised FLC Manifold Learning")
        print("="*60)
        print("  ç‰©ç†åˆ¶ç´„ã®ã¿ã§FLCé¢ã‚’äº‹å‰å­¦ç¿’")
    
    # Phase 0: æ•™å¸«ãªã—FLCé¢å­¦ç¿’
    def loss_phase0(raw_params):
        """ç‰©ç†åˆ¶ç´„ã®ã¿ã§FLCé¢ã‚’å­¦ç¿’"""
        edr_dict = transform_params_jax(raw_params)
        
        # Î²ã‚°ãƒªãƒƒãƒ‰ã‚’é©åº¦ã«è¨­å®šï¼ˆå®‰å®šç‰ˆãªã®ã§å¤šå°‘å¢—ã‚„ã›ã‚‹ï¼‰
        beta_grid = jnp.linspace(-0.8, 0.8, 13)  # 7â†’13ç‚¹ã«å¢—åŠ 
        
        # å„Î²ã§ã®ä»®æƒ³FLCé™ç•Œã‚’è¨ˆç®—
        Em_grid = []
        for beta in beta_grid:
            Em, _ = predict_flc_jax_stable(beta, edr_dict, mat_dict)  # å®‰å®šç‰ˆã‚’ä½¿ç”¨
            # NaNãƒã‚§ãƒƒã‚¯ã¨ç¯„å›²åˆ¶é™
            Em = jnp.where(jnp.isnan(Em), 0.3, Em)  
            Em = jnp.clip(Em, 0.1, 0.8)  # ã‚ˆã‚Šä¿å®ˆçš„ãªç¯„å›²
            Em_grid.append(Em)
        
        Em_array = jnp.array(Em_grid)
        Em_array = jnp.where(jnp.isnan(Em_array), 0.3, Em_array)  # æœ€çµ‚NaNãƒã‚§ãƒƒã‚¯
        
        # ç‰©ç†åˆ¶ç´„1: å˜èª¿æ€§ï¼ˆ|Îµ|ãŒå¢—ãˆã‚‹ã¨Î›ã‚‚å¢—ãˆã‚‹ï¼‰
        monotonicity_loss = jnp.mean(jnp.maximum(0, -jnp.diff(jnp.abs(Em_array))))
        monotonicity_loss = jnp.where(jnp.isnan(monotonicity_loss), 0.0, monotonicity_loss)
        
        # ç‰©ç†åˆ¶ç´„2: å‡¸æ€§ï¼ˆVå­—å½¢çŠ¶ï¼‰
        center = len(beta_grid) // 2
        left_branch = Em_array[:center]
        right_branch = Em_array[center:]
        
        # å·¦æã¯ä¸‹é™ã€å³æã¯ä¸Šæ˜‡
        convexity_loss = jnp.mean(jnp.maximum(0, jnp.diff(left_branch))) + \
                         jnp.mean(jnp.maximum(0, -jnp.diff(right_branch)))
        convexity_loss = jnp.where(jnp.isnan(convexity_loss), 0.0, convexity_loss)
        
        # ç‰©ç†åˆ¶ç´„3: å¯¾ç§°æ€§ï¼ˆç ´ã‚Œã‚’è¨±å®¹ï¼‰
        asymmetry_factor = jnp.clip(edr_dict['beta_A_pos'] / (edr_dict['beta_A'] + 1e-8), 0.5, 2.0)
        symmetry_target = Em_array[::-1] * asymmetry_factor
        symmetry_loss = 0.1 * jnp.mean((Em_array - symmetry_target)**2)
        symmetry_loss = jnp.where(jnp.isnan(symmetry_loss), 0.0, symmetry_loss)
        
        # ç‰©ç†åˆ¶ç´„4: å¹³æ»‘æ€§ï¼ˆæ€¥æ¿€ãªå¤‰åŒ–ã‚’æŠ‘åˆ¶ï¼‰
        grad2 = jnp.diff(jnp.diff(Em_array))
        smoothness_loss = 0.05 * jnp.mean(grad2**2)
        smoothness_loss = jnp.where(jnp.isnan(smoothness_loss), 0.0, smoothness_loss)
        
        # ç‰©ç†åˆ¶ç´„5: åˆç†çš„ãªç¯„å›²ï¼ˆ0.1 < Em < 1.0ï¼‰
        range_loss = jnp.mean(jnp.maximum(0, 0.1 - Em_array)**2) + \
                     jnp.mean(jnp.maximum(0, Em_array - 1.0)**2)
        range_loss = jnp.where(jnp.isnan(range_loss), 0.0, range_loss)
        
        total_loss = monotonicity_loss + convexity_loss + symmetry_loss + \
                    smoothness_loss + range_loss
        
        # æœ€çµ‚NaNå¯¾ç­–
        total_loss = jnp.where(jnp.isnan(total_loss), 1e10, total_loss)
        
        return total_loss
    
    # Phase 0ã®åˆæœŸåŒ–
    params_phase0 = init_edr_params_jax()
    
    # Phase 0æœ€é©åŒ–ï¼ˆå®‰å®šç‰ˆãªã®ã§å­¦ç¿’ç‡ã‚’é©åº¦ã«ï¼‰
    schedule_phase0 = optax.exponential_decay(
        init_value=3e-3,  # 1e-3â†’3e-3ã«æˆ»ã™
        transition_steps=50,  
        decay_rate=0.92  # 0.95â†’0.92
    )
    
    optimizer_phase0 = optax.chain(
        optax.clip_by_global_norm(1.0),
        optax.adam(learning_rate=schedule_phase0)
    )
    
    opt_state_phase0 = optimizer_phase0.init(params_phase0)
    grad_fn_phase0 = jax.grad(loss_phase0)
    
    for step in range(300):  # å…ƒã«æˆ»ã™
        grads = grad_fn_phase0(params_phase0)
        updates, opt_state_phase0 = optimizer_phase0.update(grads, opt_state_phase0, params_phase0)
        params_phase0 = optax.apply_updates(params_phase0, updates)
        
        if step % 100 == 0 and verbose:  # å…ƒã«æˆ»ã™
            loss = loss_phase0(params_phase0)
            print(f"  Step {step:3d}: Physics Loss = {loss:.6f}")
    
    if verbose:
        final_loss_phase0 = loss_phase0(params_phase0)
        print(f"\n  Phase 0å®Œäº†: Physics Loss = {final_loss_phase0:.6f}")
        print("  ç‰©ç†çš„ã«å¦¥å½“ãªFLCé¢ã®åˆæœŸåŒ–å®Œäº†")
    
    # Phase 0ã®çµæœã‚’åˆæœŸå€¤ã¨ã—ã¦ä½¿ç”¨
    params_jax = params_phase0
    
    # ===========================
    # Phase 1: AdamWåºƒåŸŸæ¢ç´¢
    # ===========================
    if verbose:
        print("\n" + "="*60)
        print(" Phase 1: JAX + AdamW åºƒåŸŸæ¢ç´¢")
        print("="*60)
        print("  Phase 0ã§å­¦ç¿’ã—ãŸFLCé¢ã‚’åŸºã«ã€ãƒã‚¤ãƒŠãƒªåˆ†é¡ã‚’æœ€é©åŒ–")
    
    # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶è¨­å®š
    schedule = optax.warmup_cosine_decay_schedule(
        init_value=1e-2,
        peak_value=1e-2,
        warmup_steps=100,
        decay_steps=1900,
        end_value=1e-4
    )
    
    optimizer = optax.chain(
        optax.clip_by_global_norm(1.0),
        optax.adamw(learning_rate=schedule, weight_decay=1e-3, b1=0.9, b2=0.999)
    )
    
    opt_state = optimizer.init(params_jax)
    grad_fn = jax.grad(loss_fn_jax)
    
    # æœ€é©åŒ–ãƒ«ãƒ¼ãƒ—
    best_loss = float('inf')
    best_params = params_jax
    
    for step in range(2000):
        grads = grad_fn(params_jax, exps, mat)
        updates, opt_state = optimizer.update(grads, opt_state, params_jax)
        params_jax = optax.apply_updates(params_jax, updates)
        
        if step % 100 == 0:
            loss = loss_fn_jax(params_jax, exps, mat)
            if loss < best_loss:
                best_loss = loss
                best_params = params_jax
            
            if verbose:
                print(f"  Step {step:4d}: Loss = {loss:.6f}")
    
    # Phase 1çµæœã‚’å¤‰æ›
    edr_dict = transform_params_jax(best_params)
    edr_phase1 = edr_dict_to_dataclass(edr_dict)
    
    if verbose:
        print(f"\n  Phase 1å®Œäº†: æœ€çµ‚Loss = {best_loss:.6f}")
    
    # ===========================
    # Phase 1.5: FLC Shaping
    # ===========================
    if flc_pts and verbose:
        print("\n" + "="*60)
        print(" Phase 1.5: FLC Shaping (AdamW)")
        print("="*60)
        print("  FLCå½¢çŠ¶ã®å­¦ç¿’ã«ç‰¹åŒ–")
    
    # FLCå°‚ç”¨æå¤±é–¢æ•°ï¼ˆçœŸç‰©ç†ç‰ˆï¼‰
    def loss_flc_true_jax(raw_params, flc_pts_data, mat_dict):
        """çœŸã®Î›ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹FLCæå¤±"""
        edr_dict = transform_params_jax(raw_params)
        
        # FLCç‚¹ã”ã¨ã®èª¤å·®ã‚’é †æ¬¡è¨ˆç®—ï¼ˆvmapã®ä»£ã‚ã‚Šã«ãƒ«ãƒ¼ãƒ—ï¼‰
        flc_err = 0.0
        for i in range(len(flc_pts_data['path_ratios'])):
            beta = flc_pts_data['path_ratios'][i]
            Em_gt = flc_pts_data['major_limits'][i]
            em_gt = flc_pts_data['minor_limits'][i]
            
            Em_pred, em_pred, _ = predict_flc_from_sim_jax(beta, mat_dict, edr_dict)
            
            # Î²ä¾å­˜ã®é‡ã¿ä»˜ã‘ï¼ˆç­‰äºŒè»¸ã‚’æœ€é‡è¦–ï¼‰
            w = jnp.where(jnp.abs(beta - 0.5) < 0.1, 6.0,
                         jnp.where(jnp.abs(beta) < 0.1, 1.8, 1.0))
            
            flc_err += w * ((Em_pred - Em_gt)**2 + (em_pred - em_gt)**2)
        
        flc_err = flc_err / len(flc_pts_data['path_ratios'])
        
        # Vå­—å½¢çŠ¶ã¨æ»‘ã‚‰ã‹ã•ã®æ­£å‰‡åŒ–ï¼ˆé«˜è§£åƒåº¦ã«æˆ»ã™ï¼‰
        beta_batch = jnp.linspace(-0.6, 0.6, 21)  # 7â†’21ç‚¹ã«æˆ»ã™ï¼
        
        # æ­£å‰‡åŒ–ç”¨ã®FLCæ›²ç·šã‚’è¨ˆç®—ï¼ˆãƒ«ãƒ¼ãƒ—ä½¿ç”¨ï¼‰
        Em_curve = []
        for beta in beta_batch:
            Em, _, _ = predict_flc_from_sim_jax(beta, mat_dict, edr_dict)
            Em_curve.append(Em)
        Em_curve = jnp.array(Em_curve)
        
        # Vå­—å½¢çŠ¶ã®æ­£å‰‡åŒ–
        center_idx = len(beta_batch) // 2
        center = Em_curve[center_idx]
        valley_loss = 0.1 * jnp.mean(jnp.maximum(0.0, Em_curve - center))
        
        # æ›²ç‡ã®æ­£å‰‡åŒ–ï¼ˆæ»‘ã‚‰ã‹ã•ï¼‰
        grad2 = jnp.diff(jnp.diff(Em_curve))
        smoothness_loss = 0.05 * jnp.mean(grad2**2) + 0.02 * jnp.mean(jnp.abs(grad2))
        
        # å‹•çš„é‡ã¿ä»˜ã‘ï¼ˆåˆ†æ•£ã«å¿œã˜ã¦æ­£å‰‡åŒ–ã‚’èª¿æ•´ï¼‰
        valley_weight = jnp.clip(jnp.var(Em_curve), 0.05, 0.3)
        valley_loss = valley_weight * valley_loss
        
        total_loss = flc_err + valley_loss + smoothness_loss
        
        return total_loss
    
    # æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›æ€§ã®ãŸã‚ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹
    loss_flc_jax = loss_flc_true_jax
    
    # FLCæœ€é©åŒ–å®Ÿè¡Œ
    if flc_pts:
        # ä»®æƒ³FLCç‚¹ã‚’è¿½åŠ ï¼ˆãƒ‡ãƒ¼ã‚¿å¢—å¼·ï¼‰
        virtual_flc_pts = [
            FLCPoint(-0.3, 0.32, -0.096, 0.6, 1.0, "virtual_1"),  # æ·±çµã‚Š-å¹³é¢ã®ä¸­é–“
            FLCPoint(0.3, 0.25, 0.075, 0.6, 1.0, "virtual_2"),    # å¹³é¢-ç­‰äºŒè»¸ã®ä¸­é–“
            FLCPoint(-0.7, 0.38, -0.266, 0.6, 1.0, "virtual_3"),  # ã‚ˆã‚Šæ·±çµã‚Šå´
            FLCPoint(0.7, 0.18, 0.126, 0.6, 1.0, "virtual_4"),    # ã‚ˆã‚Šç­‰äºŒè»¸å´
        ]
        
        # å®Ÿãƒ‡ãƒ¼ã‚¿ã¨ä»®æƒ³ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
        all_flc_pts = flc_pts + virtual_flc_pts
        
        # FLCãƒ‡ãƒ¼ã‚¿ã‚’JAXå½¢å¼ã«å¤‰æ›
        flc_pts_data = {
            'path_ratios': jnp.array([p.path_ratio for p in all_flc_pts]),
            'major_limits': jnp.array([p.major_limit for p in all_flc_pts]),
            'minor_limits': jnp.array([p.minor_limit for p in all_flc_pts])
        }
        
        # å­¦ç¿’ç‡ã‚’é«˜ã‚ã«è¨­å®šï¼ˆwarmupä»˜ãã€å¼·åŒ–ç‰ˆï¼‰
        schedule_flc = optax.warmup_cosine_decay_schedule(
            init_value=2e-3,
            peak_value=5e-3,  # ã‚ˆã‚Šç©æ¥µçš„ãªå­¦ç¿’
            warmup_steps=200,
            decay_steps=1300,
            end_value=5e-4
        )
        
        optimizer_flc = optax.chain(
            optax.clip_by_global_norm(0.3),  # ã‚ˆã‚Šå°ã•ã„clip
            optax.adamw(learning_rate=schedule_flc, weight_decay=5e-5)
        )
        
        opt_state_flc = optimizer_flc.init(best_params)
        mat_dict = mat_to_jax_dict(mat)
        grad_fn_flc = jax.grad(loss_flc_true_jax)  # çœŸç‰©ç†ç‰ˆã‚’ä½¿ç”¨
        
        params_flc = best_params
        
        # ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¤§å¹…å¢—åŠ 
        for step in range(1500):
            grads = grad_fn_flc(params_flc, flc_pts_data, mat_dict)
            updates, opt_state_flc = optimizer_flc.update(grads, opt_state_flc, params_flc)
            params_flc = optax.apply_updates(params_flc, updates)
            
            if step % 300 == 0 and verbose:
                loss = loss_flc_true_jax(params_flc, flc_pts_data, mat_dict)
                print(f"  Step {step:4d}: FLC Loss = {loss:.6f}")
        
        # Phase 1.5çµæœã‚’ä½¿ç”¨
        best_params = params_flc
        edr_dict = transform_params_jax(best_params)
        edr_phase1 = edr_dict_to_dataclass(edr_dict)
        
        if verbose:
            final_flc_loss = loss_flc_true_jax(params_flc, flc_pts_data, mat_dict)
            print(f"\n  Phase 1.5å®Œäº†: FLC Loss = {final_flc_loss:.6f}")
            print("  çœŸç‰©ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ã®FLCå½¢çŠ¶å­¦ç¿’å®Œäº†")
    
    # ===========================
    # Phase 2: L-BFGS-Bå±€æ‰€ç²¾å¯†åŒ–
    # ===========================
    
    # Phase 1ãŒååˆ†åæŸã—ã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    if best_loss < 1e-5:
        if verbose:
            print("\n" + "="*60)
            print(" Phase 2: ã‚¹ã‚­ãƒƒãƒ—ï¼ˆPhase 1ã§ååˆ†åæŸï¼‰")
            print("="*60)
            print(f"  Phase 1 Loss = {best_loss:.6f} < 1e-5")
            print("  L-BFGS-Bã¯ä¸è¦ã¨åˆ¤æ–­")
        
        edr_phase2 = edr_phase1
        res = type('obj', (), {'fun': best_loss, 'nit': 0})()  # ãƒ€ãƒŸãƒ¼result
    else:
        if verbose:
            print("\n" + "="*60)
            print(" Phase 2: L-BFGS-B å±€æ‰€ç²¾å¯†åŒ–")
            print("="*60)
        
        # NumPyç‰ˆã®æå¤±é–¢æ•°ï¼ˆL-BFGS-Bç”¨ï¼‰
        def loss_numpy(theta):
            edr = EDRParams(
            V0=theta[0], av=theta[1], ad=theta[2], chi=theta[3],
            K_scale=theta[4], triax_sens=theta[5], Lambda_crit=theta[6],
            K_scale_draw=theta[7], K_scale_plane=theta[8], K_scale_biax=theta[9],
            beta_A=theta[10], beta_bw=theta[11], beta_A_pos=theta[12]
            )
            
            # JAXã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
            mat_dict = mat_to_jax_dict(mat)
            edr_dict = {
            'V0': edr.V0, 'av': edr.av, 'ad': edr.ad, 'chi': edr.chi,
            'K_scale': edr.K_scale, 'triax_sens': edr.triax_sens,
            'Lambda_crit': edr.Lambda_crit,
            'K_scale_draw': edr.K_scale_draw,
            'K_scale_plane': edr.K_scale_plane,
            'K_scale_biax': edr.K_scale_biax,
            'beta_A': edr.beta_A, 'beta_bw': edr.beta_bw,
            'beta_A_pos': edr.beta_A_pos
            }
            
            total_loss = 0.0
            for exp in exps:
                schedule_dict = schedule_to_jax_dict(exp.schedule)
                loss = loss_single_exp_jax(schedule_dict, mat_dict, edr_dict, exp.failed)
                total_loss += float(loss)
            
            # FLCæå¤±ã‚‚è¿½åŠ ï¼ˆÎ²é‡ã¿ä»˜ã‘ç‰ˆï¼šç­‰äºŒè»¸ã‚’ã‚ˆã‚Šé‡è¦–ï¼‰
            if flc_pts:
                for p in flc_pts:
                    # ç­‰äºŒè»¸ï¼ˆÎ²â‰ˆ0.5ï¼‰ã‚’æœ€é‡è¦è¦–ã€å¹³é¢ã²ãšã¿ï¼ˆÎ²â‰ˆ0ï¼‰ã‚‚é‡è¦–
                    if abs(p.path_ratio - 0.5) < 0.1:
                        w = 5.0  # ç­‰äºŒè»¸ã¯5å€é‡ã¿
                    elif abs(p.path_ratio) < 0.1:
                        w = 1.5  # å¹³é¢ã²ãšã¿ã¯1.5å€
                    else:
                        w = 1.0  # æ·±çµã‚Šã¯é€šå¸¸
                        
                    Em, em = predict_FLC_point(p.path_ratio, p.rate_major, p.duration_max, mat, edr)
                    flc_loss = ((Em - p.major_limit)**2 + (em - p.minor_limit)**2)
                    total_loss += w * flc_loss * 0.8
            
            return total_loss / max(len(exps), 1)
        
        # åˆæœŸå€¤ã¨å¢ƒç•Œ
        theta0 = np.array([
            edr_phase1.V0, edr_phase1.av, edr_phase1.ad, edr_phase1.chi,
            edr_phase1.K_scale, edr_phase1.triax_sens, edr_phase1.Lambda_crit,
            edr_phase1.K_scale_draw, edr_phase1.K_scale_plane, edr_phase1.K_scale_biax,
            edr_phase1.beta_A, edr_phase1.beta_bw, edr_phase1.beta_A_pos
        ])
        
        bounds = [
            (5e8, 5e9),       # V0
            (1e4, 1e6),       # av
            (1e-8, 1e-6),     # ad
            (0.05, 0.3),      # chi
            (0.05, 1.0),      # K_scale
            (0.1, 0.5),       # triax_sens
            (0.95, 1.05),     # Lambda_crit
            (0.05, 0.3),      # K_scale_draw
            (0.1, 0.4),       # K_scale_plane
            (0.05, 0.3),      # K_scale_biax
            (0.2, 0.5),       # beta_A
            (0.2, 0.35),      # beta_bw
            (0.3, 0.7),       # beta_A_pos
        ]
        
        res = minimize(loss_numpy, theta0, method='L-BFGS-B', bounds=bounds,
                      options={'maxiter': 100, 'ftol': 1e-10})
        
        edr_phase2 = EDRParams(
            V0=res.x[0], av=res.x[1], ad=res.x[2], chi=res.x[3],
            K_scale=res.x[4], triax_sens=res.x[5], Lambda_crit=res.x[6],
            K_scale_draw=res.x[7], K_scale_plane=res.x[8], K_scale_biax=res.x[9],
            beta_A=res.x[10], beta_bw=res.x[11], beta_A_pos=res.x[12]
        )
        
        if verbose:
            print(f"  Phase 2å®Œäº†: æœ€çµ‚Loss = {res.fun:.6f}")
            print(f"  Iterations: {res.nit}")
    
    # ===========================
    # Phase 3: ã‚¹ã‚­ãƒƒãƒ—ï¼ˆFLCå½¢çŠ¶å­¦ç¿’å¾Œã¯ä¸è¦ï¼‰
    # ===========================
    if verbose:
        print("\n" + "="*60)
        print(" Phase 3: ã‚¹ã‚­ãƒƒãƒ—ï¼ˆFLCå½¢çŠ¶å­¦ç¿’å¾Œã¯å¾®èª¿æ•´ä¸è¦ï¼‰")
        print("="*60)
        print("  Phase 1.5ã§ååˆ†ã«æœ€é©åŒ–æ¸ˆã¿")
    
    # Phase 1.5ï¼ˆã¾ãŸã¯Phase 2ï¼‰ã®çµæœã‚’ãã®ã¾ã¾ä½¿ç”¨
    if 'params_flc' in locals():
        # Phase 1.5å®Ÿè¡Œæ™‚
        edr_dict_final = transform_params_jax(params_flc)
        edr_final = edr_dict_to_dataclass(edr_dict_final)
        final_loss = loss_flc_true_jax(params_flc, flc_pts_data, mat_dict)
    else:
        # Phase 1.5ã‚¹ã‚­ãƒƒãƒ—æ™‚ã¯Phase 2ã®çµæœã‚’ä½¿ç”¨
        edr_final = edr_phase2
        final_loss = 0.0
    
    info = {
        'success': True,
        'final_loss': float(final_loss),
        'phase1_loss': float(best_loss),
        'phase2_loss': float(res.fun),
        'phase2_iterations': res.nit,
    }
    
    if verbose:
        print(f"\n  Phase 3å®Œäº†: æœ€çµ‚Loss = {final_loss:.6f}")
        print("\n" + "="*60)
        print(" æœ€é©åŒ–å®Œäº†ï¼")
        print("="*60)
        
        # Final Validation
        print("\n=== Final Validation ===")
        mat_dict = mat_to_jax_dict(mat)
        correct = 0
        for i, exp in enumerate(exps):
            schedule_dict = schedule_to_jax_dict(exp.schedule)
            res = simulate_lambda_jax(schedule_dict, mat_dict, edr_dict_final)
            Lambda_smooth = smooth_signal_jax(res["Lambda"], window_size=11)
            peak = float(jnp.max(Lambda_smooth))
            D_end = float(res["Damage"][-1])
            
            Dcrit = 0.01
            if exp.failed == 1:
                passed = (peak > edr_final.Lambda_crit and D_end > Dcrit)
            else:
                passed = (peak < edr_final.Lambda_crit - 0.03)
            
            if passed:
                correct += 1
                status = "âœ“"
            else:
                status = "âœ—"
                
            print(f"Exp{i}({exp.label}): Î›_max={peak:.3f}, D={D_end:.4f}, "
                  f"failed={exp.failed}, {status}")
        
        accuracy = correct / len(exps) * 100
        print(f"Accuracy: {accuracy:.2f}%")
        final_binary_loss = loss_fn_jax(params_jax_final, exps, mat)
        print(f"Final binary loss: {final_binary_loss:.4f}")
    
    return edr_final, info

# =============================================================================
# Section 6: ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# =============================================================================

def predict_FLC_point(path_ratio: float, major_rate: float, duration_max: float,
                     mat: MaterialParams, edr: EDRParams,
                     base_contact: float=1.0, base_mu: float=0.08,
                     base_pN: float=200e6, base_vslip: float=0.02,
                     base_htc: float=8000.0, Tdie: float=293.15,
                     T0: float=293.15) -> Tuple[float, float]:
    """FLCç‚¹äºˆæ¸¬"""
    dt = 1e-3
    N = int(duration_max/dt) + 1
    t = np.linspace(0, duration_max, N)
    epsM = major_rate * t
    epsm = path_ratio * major_rate * t
    
    schedule = PressSchedule(
        t=t, eps_maj=epsM, eps_min=epsm,
        triax=np.full(N, triax_from_path_jax(path_ratio)),
        mu=np.full(N, base_mu), pN=np.full(N, base_pN),
        vslip=np.full(N, base_vslip), htc=np.full(N, base_htc),
        Tdie=np.full(N, Tdie), contact=np.full(N, base_contact), T0=T0
    )
    
    # JAXç‰ˆã§å®Ÿè¡Œ
    schedule_dict = schedule_to_jax_dict(schedule)
    mat_dict = mat_to_jax_dict(mat)
    edr_dict = {
        'V0': edr.V0, 'av': edr.av, 'ad': edr.ad, 'chi': edr.chi,
        'K_scale': edr.K_scale, 'triax_sens': edr.triax_sens,
        'Lambda_crit': edr.Lambda_crit,
        'K_scale_draw': edr.K_scale_draw,
        'K_scale_plane': edr.K_scale_plane,
        'K_scale_biax': edr.K_scale_biax,
        'beta_A': edr.beta_A, 'beta_bw': edr.beta_bw,
        'beta_A_pos': edr.beta_A_pos
    }
    
    res = simulate_lambda_jax(schedule_dict, mat_dict, edr_dict)
    Lambda = np.array(res["Lambda"])
    
    # ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°å‡¦ç†ï¼ˆé‡è¦ï¼ï¼‰
    Lambda_smooth = smooth_signal_jax(Lambda, window_size=11)
    
    # é™ç•Œç‚¹ã‚’æ¢ã™
    idx = np.where(Lambda_smooth > edr.Lambda_crit)[0]
    if len(idx) > 0:
        k = idx[0]
        return float(epsM[k]), float(epsm[k])
    else:
        return float(epsM[-1]), float(epsm[-1])

def evaluate_flc_fit(experimental: List[FLCPoint],
                    predicted: List[Tuple[float, float]]) -> float:
    """FLCé©åˆåº¦è©•ä¾¡"""
    errors = []
    for exp, pred in zip(experimental, predicted):
        deM = pred[0] - exp.major_limit
        dem = pred[1] - exp.minor_limit
        err = np.sqrt(deM**2 + dem**2)
        errors.append(err)
        print(f"  Î²={exp.path_ratio:+.1f}: èª¤å·®={err:.4f} (Î”Maj={deM:+.3f}, Î”Min={dem:+.3f})")
    
    mean_err = np.mean(errors)
    max_err = np.max(errors)
    
    print(f"\nFLCé©åˆåº¦è©•ä¾¡:")
    print(f"  å¹³å‡èª¤å·®: {mean_err:.4f}")
    print(f"  æœ€å¤§èª¤å·®: {max_err:.4f}")
    print(f"  ç²¾åº¦è©•ä¾¡: ", end="")
    
    if mean_err < 0.05:
        print("âœ… å„ªç§€ï¼ˆ<5%ï¼‰")
    elif mean_err < 0.10:
        print("ğŸŸ¡ è‰¯å¥½ï¼ˆ<10%ï¼‰")
    elif mean_err < 0.20:
        print("ğŸŸ  è¦æ”¹å–„ï¼ˆ<20%ï¼‰")
    else:
        print("ğŸ”´ ä¸è‰¯ï¼ˆ>20%ï¼‰")
    
    return mean_err

# =============================================================================
# Section 7: ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
# =============================================================================

def generate_demo_experiments() -> List[ExpBinary]:
    """ãƒ‡ãƒ¢å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    def mk_schedule(beta, mu_base, mu_jump=False, high_stress=False):
        dt = 1e-3
        T = 0.6
        t = np.arange(0, T+dt, dt)
        
        if high_stress:
            epsM = 0.5 * (t/T)**0.8
        else:
            epsM = 0.35 * (t/T)
        epsm = beta * epsM
        
        mu = np.full_like(t, mu_base)
        if mu_jump:
            j = int(0.25/dt)
            mu[j:] += 0.06
        
        triax_val = float(triax_from_path_jax(beta))
        
        return PressSchedule(
            t=t, eps_maj=epsM, eps_min=epsm,
            triax=np.full_like(t, triax_val), mu=mu,
            pN=np.full_like(t, 250e6 if high_stress else 200e6),
            vslip=np.full_like(t, 0.03), htc=np.full_like(t, 8000.0),
            Tdie=np.full_like(t, 293.15), contact=np.full_like(t, 1.0), T0=293.15
        )
    
    exps = [
        ExpBinary(mk_schedule(-0.5, 0.08, False, False), failed=0, label="safe_draw"),
        ExpBinary(mk_schedule(-0.5, 0.08, True, True), failed=1, label="draw_fail"),
        ExpBinary(mk_schedule(0.0, 0.08, False, False), failed=0, label="safe_plane"),
        ExpBinary(mk_schedule(0.0, 0.08, True, True), failed=1, label="plane_fail"),
        ExpBinary(mk_schedule(0.5, 0.10, False, False), failed=0, label="safe_biax"),
        ExpBinary(mk_schedule(0.5, 0.10, True, True), failed=1, label="biax_fail"),
    ]
    return exps

def generate_demo_flc() -> List[FLCPoint]:
    """ãƒ‡ãƒ¢FLCãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    return [
        FLCPoint(-0.5, 0.35, -0.175, 0.6, 1.0, "draw"),
        FLCPoint(0.0, 0.28, 0.0, 0.6, 1.0, "plane"),
        FLCPoint(0.5, 0.22, 0.11, 0.6, 1.0, "biax"),
    ]

# =============================================================================
# Section 8: ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# =============================================================================

if __name__ == "__main__":
    print("="*80)
    print(" EDRãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°çµ±åˆç‰ˆ v5.0")
    print(" Inverse-EDR Neural Calibration Engine (IENCE)")
    print("="*80)
    
    # ææ–™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    mat = MaterialParams()
    
    # ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    print("\n[ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ]")
    exps = generate_demo_experiments()
    flc_data = generate_demo_flc()
    print(f"  å®Ÿé¨“æ•°: {len(exps)}")
    print(f"  FLCç‚¹æ•°: {len(flc_data)}")
    
    # 3ãƒ•ã‚§ãƒ¼ã‚ºHybridæœ€é©åŒ–å®Ÿè¡Œ
    edr_fit, info = hybrid_staged_optimization(
        exps, flc_data, mat,
        verbose=True
    )
    
    # çµæœè¡¨ç¤º
    print("\n" + "="*60)
    print(" æœ€çµ‚çµæœ")
    print("="*60)
    print(f"\næœ€çµ‚Loss: {info['final_loss']:.6f}")
    print(f"Phase1 Loss: {info['phase1_loss']:.6f}")
    print(f"Phase2 Loss: {info['phase2_loss']:.6f}")
    
    print(f"\nEDR Parameters:")
    print(f"  V0: {edr_fit.V0:.2e} Pa")
    print(f"  av: {edr_fit.av:.2e}")
    print(f"  ad: {edr_fit.ad:.2e}")
    print(f"  chi: {edr_fit.chi:.3f}")
    print(f"  K_scale: {edr_fit.K_scale:.3f}")
    print(f"  triax_sens: {edr_fit.triax_sens:.3f}")
    print(f"  Lambda_crit: {edr_fit.Lambda_crit:.3f}")
    print(f"  K_scale_draw: {edr_fit.K_scale_draw:.3f}")
    print(f"  K_scale_plane: {edr_fit.K_scale_plane:.3f}")
    print(f"  K_scale_biax: {edr_fit.K_scale_biax:.3f}")
    print(f"  beta_A: {edr_fit.beta_A:.3f}")
    print(f"  beta_bw: {edr_fit.beta_bw:.3f}")
    print(f"  beta_A_pos: {edr_fit.beta_A_pos:.3f} (éå¯¾ç§°)")
    
    # FLCäºˆæ¸¬
    print("\n[FLCäºˆæ¸¬]")
    preds = []
    for p in flc_data:
        Em, em = predict_FLC_point(p.path_ratio, p.rate_major, p.duration_max, mat, edr_fit)
        preds.append((Em, em))
        print(f"  Î²={p.path_ratio:+.1f}: å®Ÿæ¸¬({p.major_limit:.3f}, {p.minor_limit:.3f}) "
              f"â†’ äºˆæ¸¬({Em:.3f}, {em:.3f})")
    
    flc_error = evaluate_flc_fit(flc_data, preds)
    
    print("\n" + "="*80)
    print(" å®Ÿè¡Œå®Œäº†ï¼")
    print(" éå¯¾ç§°FLCå¯¾å¿œãƒ»3ãƒ•ã‚§ãƒ¼ã‚ºæœ€é©åŒ–å®Œæˆ âœ…")
    print("="*80)
