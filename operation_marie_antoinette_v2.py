"""
=============================================================================
Operation Marie Antoinette v2.0: Inverse Problem Data Augmentation
"ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãªã‚‰ä½œã‚Œã°ã„ã„ã˜ã‚ƒãªã„ï¼"

é€†å•é¡ŒÃ—å¤šæ§˜ä½“å­¦ç¿’Ã—ã‚¤ãƒ™ãƒ³ãƒˆã‚°ãƒ©ãƒ ã«ã‚ˆã‚‹ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆç ´æ–­åˆ¤å®š

ã€edr_fit.pyå®Œå…¨çµ±åˆç‰ˆ v2.0ã€‘
âœ… edr_fit.pyã®æ©Ÿèƒ½ã‚’ãƒ•ãƒ«æ´»ç”¨
âœ… é‡è¤‡ã‚³ãƒ¼ãƒ‰å®Œå…¨å‰Šæ¸›
âœ… ä¾å­˜é–¢ä¿‚ã®æ˜ç¢ºåŒ–
âœ… ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ€§å‘ä¸Š
âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

Author: é£¯æ³‰çœŸé“ + ç’°
Date: 2025-10-07 (v2.0çµ±åˆç‰ˆ)
=============================================================================
"""

import jax
import jax.numpy as jnp
from jax import jit, vmap
import numpy as np
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass

# =============================================================================
# edr_fit.pyã‹ã‚‰å¿…è¦ãªæ©Ÿèƒ½ã‚’ä¸€æ‹¬importï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
# =============================================================================
try:
    from edr_fit import (
        # === ã‚³ã‚¢ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ===
        simulate_lambda_jax,
        
        # === ãƒ‡ãƒ¼ã‚¿å¤‰æ›é–¢æ•° ===
        schedule_to_jax_dict,
        mat_to_jax_dict,
        transform_params_jax,
        edr_dict_to_dataclass,
        
        # === ç‰©ç†è¨ˆç®—ãƒ˜ãƒ«ãƒ‘ãƒ¼ ===
        triax_from_path_jax,
        equiv_strain_rate_jax,
        smooth_signal_jax,
        
        # === æå¤±é–¢æ•° ===
        loss_flc_true_jax,
        loss_fn_jax,
        loss_single_exp_jax,
        
        # === ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç®¡ç† ===
        init_edr_params_jax,
        
        # === ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ ===
        MaterialParams,
        EDRParams,
        PressSchedule,
        ExpBinary,
        FLCPoint,
    )
    EDR_FIT_AVAILABLE = True
    print("âœ“ edr_fit.pyå®Œå…¨çµ±åˆ: å…¨æ©Ÿèƒ½ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    EDR_FIT_AVAILABLE = False
    print(f"âš ï¸  edr_fit.pyã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    print("   operation_marie_antoinette.pyã¯edr_fit.pyã«ä¾å­˜ã—ã¾ã™")
    print("   å˜ä½“å®Ÿè¡Œã®å ´åˆã¯ã€edr_fit.pyã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã—ã¦ãã ã•ã„")

# optaxï¼ˆæœ€é©åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼‰
try:
    import optax
    OPTAX_AVAILABLE = True
except ImportError:
    OPTAX_AVAILABLE = False
    print("âš ï¸  optaxãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install optax")

# =============================================================================
# Section 1: Gramè¡Œåˆ—ã¨ã‚¤ãƒ™ãƒ³ãƒˆè¡¨ç¾
# =============================================================================

@jit
def compute_gram(x):
    """
    Gramè¡Œåˆ—è¨ˆç®—ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«ä¸å¤‰ç‰ˆï¼‰
    
    Args:
        x: [time] ã¾ãŸã¯ [batch, time]
    Returns:
        Gramè¡Œåˆ— [time, time]
    """
    # 0-meanåŒ–
    x_centered = x - jnp.mean(x, axis=-1, keepdims=True)
    # L2æ­£è¦åŒ–
    x_norm = x_centered / (jnp.linalg.norm(x_centered, axis=-1, keepdims=True) + 1e-8)
    # Gramè¡Œåˆ—
    if x_norm.ndim == 1:
        return jnp.outer(x_norm, x_norm)
    else:
        return x_norm @ x_norm.T

@jit
def gram_distance(G1, G2):
    """2ã¤ã®Gramè¡Œåˆ—é–“ã®è·é›¢"""
    return jnp.sum((G1 - G2)**2)

# =============================================================================
# Section 2: æ­£å‰‡åŒ–é …ï¼ˆç‰©ç†çš„ç•°å¸¸æ¤œå‡ºï¼‰
# =============================================================================

@jit
def compute_tv(Lambda):
    """
    Total Variationï¼ˆå…¨å¤‰å‹•ï¼‰
    æ™‚é–“æ–¹å‘ã®æ€¥æ¿€ãªå¤‰åŒ–ã‚’æ¤œå‡º
    """
    if Lambda.ndim == 1:
        return jnp.sum(jnp.abs(jnp.diff(Lambda)))
    else:
        # [paths, time]
        tv_time = jnp.sum(jnp.abs(jnp.diff(Lambda, axis=1)))
        tv_path = jnp.sum(jnp.abs(jnp.diff(Lambda, axis=0)))
        return tv_time + tv_path

@jit
def compute_jump_penalty(Lambda, k=2.5):
    """
    Jumpæ­£å‰‡åŒ–ï¼šå¤–ã‚Œå€¤çš„ãªæ€¥å¤‰ã‚’æ¤œå‡º
    
    Args:
        Lambda: [time] ã¾ãŸã¯ [paths, time]
        k: æ¨™æº–åå·®ã®ä½•å€ã‚’é–¾å€¤ã¨ã™ã‚‹ã‹
    """
    if Lambda.ndim == 1:
        d = jnp.abs(jnp.diff(Lambda))
        threshold = jnp.mean(d) + k * jnp.std(d)
        return jnp.sum(jnp.maximum(0.0, d - threshold))
    else:
        # [paths, time-1]
        d = jnp.abs(jnp.diff(Lambda, axis=1))
        threshold = jnp.mean(d, axis=1, keepdims=True) + k * jnp.std(d, axis=1, keepdims=True)
        return jnp.sum(jnp.maximum(0.0, d - threshold))

@jit
def compute_topo_penalty(Lambda):
    """
    ä½ç›¸é€£ç¶šæ€§æ­£å‰‡åŒ–
    Phaseé·ç§»ã®æ»‘ã‚‰ã‹ã•ã‚’è©•ä¾¡
    """
    if Lambda.ndim == 1:
        # phase_k = atan2(Lambda[k+1], Lambda[k])
        phase = jnp.arctan2(Lambda[1:], Lambda[:-1])
        # ä½ç›¸å·®
        dphase = jnp.diff(phase)
        # [-Ï€, Ï€]ã«æ­£è¦åŒ–
        dphase = (dphase + jnp.pi) % (2 * jnp.pi) - jnp.pi
        return jnp.sum(dphase**2)
    else:
        # [paths, time-1]
        phase = jnp.arctan2(Lambda[:, 1:], Lambda[:, :-1])
        dphase = jnp.diff(phase, axis=1)
        dphase = (dphase + jnp.pi) % (2 * jnp.pi) - jnp.pi
        return jnp.sum(dphase**2)

@jit
def compute_l1_norm(Lambda):
    """L1æ­£å‰‡åŒ–ï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ä¿ƒé€²ï¼‰"""
    return jnp.sum(jnp.abs(Lambda))

# =============================================================================
# Section 3: Phase 0 æ•™å¸«ãªã—å­¦ç¿’ï¼ˆç‰©ç†åˆ¶ç´„ã®ã¿ï¼‰
# =============================================================================

def phase0_unsupervised_learning(
    mat_dict: Dict,
    n_steps: int = 300,
    verbose: bool = True
):
    """
    Phase 0: Unsupervised FLC Pretraining
    å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ãªã—ã§ã€ç‰©ç†åˆ¶ç´„ã®ã¿ã§EDRãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’äº‹å‰å­¦ç¿’
    
    Args:
        mat_dict: ææ–™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        n_steps: æœ€é©åŒ–ã‚¹ãƒ†ãƒƒãƒ—æ•°
        verbose: é€²æ—è¡¨ç¤º
    
    Returns:
        params_phase0: Phase 0ã§å­¦ç¿’ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆrawï¼‰
        loss_history: æå¤±å±¥æ­´
    """
    if not OPTAX_AVAILABLE:
        raise ImportError("optaxãŒå¿…è¦ã§ã™: pip install optax")
    
    if not EDR_FIT_AVAILABLE:
        raise ImportError("edr_fit.pyãŒå¿…è¦ã§ã™")
    
    if verbose:
        print("\n" + "="*60)
        print(" ğŸ‚ Phase 0: Unsupervised FLC Manifold Learning")
        print("="*60)
        print("  ç‰©ç†åˆ¶ç´„ã®ã¿ã§FLCé¢ã‚’äº‹å‰å­¦ç¿’")
        print("  å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ä¸è¦ï¼")
    
    # Phase 0ç”¨ã®å®‰å®šç‰ˆFLCäºˆæ¸¬
    def predict_flc_stable(path_ratio, edr_dict):
        """Phase 0ç”¨ã®å®‰å®šç‰ˆFLCäºˆæ¸¬ï¼ˆargmaxä½¿ç”¨ï¼‰"""
        duration = 1.0
        major_rate = 0.6
        dt = 1e-3
        N = int(duration/dt) + 1
        t = jnp.linspace(0, duration, N)
        epsM = major_rate * t
        epsm = path_ratio * epsM
        
        schedule_dict = {
            't': t,
            'eps_maj': epsM,
            'eps_min': epsm,
            'triax': jnp.full(N, triax_from_path_jax(path_ratio)),
            'mu': jnp.full(N, 0.08),
            'pN': jnp.full(N, 200e6),
            'vslip': jnp.full(N, 0.02),
            'htc': jnp.full(N, 8000.0),
            'Tdie': jnp.full(N, 293.15),
            'contact': jnp.full(N, 1.0),
            'T0': 293.15
        }
        
        res = simulate_lambda_jax(schedule_dict, mat_dict, edr_dict)
        Lambda_smooth = smooth_signal_jax(res["Lambda"], window_size=11)
        
        # å®‰å®šç‰ˆï¼šargmaxä½¿ç”¨
        exceed_mask = Lambda_smooth > edr_dict['Lambda_crit']
        first_exceed = jnp.argmax(exceed_mask)
        has_exceeded = jnp.any(exceed_mask)
        
        epsM_trimmed = epsM[:-1]
        Em = jnp.where(has_exceeded, epsM_trimmed[first_exceed], epsM_trimmed[-1])
        
        return Em
    
    # Phase 0æå¤±é–¢æ•°
    def loss_phase0(raw_params):
        """ç‰©ç†åˆ¶ç´„ã®ã¿ã§FLCé¢ã‚’å­¦ç¿’"""
        edr_dict = transform_params_jax(raw_params)
        
        beta_grid = jnp.linspace(-0.8, 0.8, 13)
        
        # å„Î²ã§ã®ä»®æƒ³FLCé™ç•Œã‚’è¨ˆç®—
        Em_grid = []
        for beta in beta_grid:
            Em = predict_flc_stable(beta, edr_dict)
            Em = jnp.where(jnp.isnan(Em), 0.3, Em)
            Em = jnp.clip(Em, 0.1, 0.8)
            Em_grid.append(Em)
        
        Em_array = jnp.array(Em_grid)
        Em_array = jnp.where(jnp.isnan(Em_array), 0.3, Em_array)
        
        # ç‰©ç†åˆ¶ç´„1: å˜èª¿æ€§
        monotonicity_loss = jnp.mean(jnp.maximum(0, -jnp.diff(jnp.abs(Em_array))))
        monotonicity_loss = jnp.where(jnp.isnan(monotonicity_loss), 0.0, monotonicity_loss)
        
        # ç‰©ç†åˆ¶ç´„2: å‡¸æ€§ï¼ˆVå­—å½¢çŠ¶ï¼‰
        center = len(beta_grid) // 2
        left_branch = Em_array[:center]
        right_branch = Em_array[center:]
        
        convexity_loss = jnp.mean(jnp.maximum(0, jnp.diff(left_branch))) + \
                         jnp.mean(jnp.maximum(0, -jnp.diff(right_branch)))
        convexity_loss = jnp.where(jnp.isnan(convexity_loss), 0.0, convexity_loss)
        
        # ç‰©ç†åˆ¶ç´„3: å¯¾ç§°æ€§ï¼ˆç ´ã‚Œã‚’è¨±å®¹ï¼‰
        asymmetry_factor = jnp.clip(edr_dict['beta_A_pos'] / (edr_dict['beta_A'] + 1e-8), 0.5, 2.0)
        symmetry_target = Em_array[::-1] * asymmetry_factor
        symmetry_loss = 0.1 * jnp.mean((Em_array - symmetry_target)**2)
        symmetry_loss = jnp.where(jnp.isnan(symmetry_loss), 0.0, symmetry_loss)
        
        # ç‰©ç†åˆ¶ç´„4: å¹³æ»‘æ€§
        grad2 = jnp.diff(jnp.diff(Em_array))
        smoothness_loss = 0.05 * jnp.mean(grad2**2)
        smoothness_loss = jnp.where(jnp.isnan(smoothness_loss), 0.0, smoothness_loss)
        
        # ç‰©ç†åˆ¶ç´„5: åˆç†çš„ãªç¯„å›²
        range_loss = jnp.mean(jnp.maximum(0, 0.1 - Em_array)**2) + \
                     jnp.mean(jnp.maximum(0, Em_array - 1.0)**2)
        range_loss = jnp.where(jnp.isnan(range_loss), 0.0, range_loss)
        
        total_loss = monotonicity_loss + convexity_loss + symmetry_loss + \
                    smoothness_loss + range_loss
        
        total_loss = jnp.where(jnp.isnan(total_loss), 1e10, total_loss)
        
        return total_loss
    
    # Phase 0åˆæœŸåŒ–
    params_phase0 = init_edr_params_jax()
    
    # Phase 0æœ€é©åŒ–
    schedule_phase0 = optax.exponential_decay(
        init_value=3e-3,
        transition_steps=50,
        decay_rate=0.92
    )
    
    optimizer_phase0 = optax.chain(
        optax.clip_by_global_norm(1.0),
        optax.adam(learning_rate=schedule_phase0)
    )
    
    opt_state_phase0 = optimizer_phase0.init(params_phase0)
    grad_fn_phase0 = jax.grad(loss_phase0)
    
    loss_history = []
    
    for step in range(n_steps):
        grads = grad_fn_phase0(params_phase0)
        updates, opt_state_phase0 = optimizer_phase0.update(grads, opt_state_phase0, params_phase0)
        params_phase0 = optax.apply_updates(params_phase0, updates)
        
        if step % 100 == 0:
            loss = float(loss_phase0(params_phase0))
            loss_history.append(loss)
            if verbose:
                print(f"  Step {step:3d}: Physics Loss = {loss:.6f}")
    
    final_loss = float(loss_phase0(params_phase0))
    loss_history.append(final_loss)
    
    if verbose:
        print(f"\n  âœ… Phase 0å®Œäº†: Physics Loss = {final_loss:.6f}")
        print("  ç‰©ç†çš„ã«å¦¥å½“ãªFLCé¢ã®åˆæœŸåŒ–å®Œäº†")
    
    return params_phase0, loss_history

# =============================================================================
# Section 4: å®‰å…¨å¤šæ§˜ä½“ã®æ§‹ç¯‰ï¼ˆedr_fit.pyå®Œå…¨çµ±åˆç‰ˆï¼‰
# =============================================================================

def build_safe_manifold(
    mat_dict: Dict,
    edr_dict: Dict,
    simulate_fn=None,
    n_beta: int = 15,
    n_mu: int = 5,
    n_pN: int = 5,
    duration: float = 0.6,  # â† å¼•æ•°ã¨ã—ã¦è¿½åŠ ï¼ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯0.6ã«
    safety_margin: float = 0.85,
    verbose: bool = True
):
    """
    å®‰å…¨ãªÎ›(t)è»Œé“ã‚’å¤§é‡ç”Ÿæˆã—ã¦å¤šæ§˜ä½“ã‚’æ§‹ç¯‰
    
    Args:
        mat_dict: ææ–™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆJAX dictï¼‰
        edr_dict: EDRãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆJAX dictï¼‰
        simulate_fn: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–¢æ•°ï¼ˆNoneãªã‚‰edr_fit.pyã®ã‚‚ã®ã‚’ä½¿ç”¨ï¼‰
        n_beta: Î²æ–¹å‘ã®ã‚µãƒ³ãƒ—ãƒ«æ•°
        n_mu: æ‘©æ“¦ä¿‚æ•°ã®ã‚µãƒ³ãƒ—ãƒ«æ•°
        n_pN: æ¥è§¦åœ§ã®ã‚µãƒ³ãƒ—ãƒ«æ•°
        safety_margin: Lambda_crit * safety_margin ä»¥ä¸‹ã‚’å®‰å…¨ã¨åˆ¤å®š
        verbose: é€²æ—è¡¨ç¤º
    
    Returns:
        safe_manifold: {
            'lambdas': [n_safe, time],
            'grams': [n_safe, time, time],
            'conditions': [n_safe] ã®æ¡ä»¶ãƒªã‚¹ãƒˆ
        }
    """
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã¯edr_fit.pyã®ã‚‚ã®ã‚’ä½¿ç”¨
    if simulate_fn is None:
        if not EDR_FIT_AVAILABLE:
            raise ImportError("simulate_lambda_jaxãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚edr_fit.pyã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„")
        simulate_fn = simulate_lambda_jax
    
    if verbose:
        print("\n" + "="*60)
        print(" ğŸ‚ Operation Marie Antoinette: å®‰å…¨å¤šæ§˜ä½“æ§‹ç¯‰")
        print("="*60)
        print(f"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“æ¢ç´¢:")
        print(f"    Î²: {n_beta}ç‚¹")
        print(f"    Î¼: {n_mu}ç‚¹")
        print(f"    pN: {n_pN}ç‚¹")
        print(f"    åˆè¨ˆ: {n_beta * n_mu * n_pN}è»Œé“ã‚’ç”Ÿæˆ")
    
    safe_lambdas = []
    safe_grams = []
    safe_conditions = []
    
    Lambda_crit = edr_dict['Lambda_crit']
    safety_threshold = Lambda_crit * safety_margin
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚°ãƒªãƒƒãƒ‰
    betas = jnp.linspace(-0.7, 0.7, n_beta)
    mus = jnp.linspace(0.05, 0.10, n_mu)
    pNs = jnp.linspace(150e6, 250e6, n_pN)
    
    count = 0
    safe_count = 0
    
    for beta in betas:
        for mu in mus:
            for pN in pNs:
                count += 1
                
                # å®‰å…¨ãªã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç”Ÿæˆï¼ˆä½è² è·ï¼‰
                duration = 0.8
                major_rate = 0.4  # ä½ã²ãšã¿é€Ÿåº¦
                dt = 1e-3
                N = int(duration/dt) + 1
                t = jnp.linspace(0, duration, N)
                epsM = major_rate * t
                epsm = beta * epsM
                
                # ä¸‰è»¸åº¦è¨ˆç®—ï¼ˆedr_fit.pyã®é–¢æ•°ã‚’ä½¿ç”¨ï¼‰
                triax_val = triax_from_path_jax(beta)
                
                schedule_dict = {
                    't': t,
                    'eps_maj': epsM,
                    'eps_min': epsm,
                    'triax': jnp.full(N, triax_val),
                    'mu': jnp.full(N, float(mu)),
                    'pN': jnp.full(N, float(pN)),
                    'vslip': jnp.full(N, 0.015),
                    'htc': jnp.full(N, 8000.0),
                    'Tdie': jnp.full(N, 293.15),
                    'contact': jnp.full(N, 1.0),
                    'T0': 293.15
                }
                
                # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œï¼ˆedr_fit.pyã®é–¢æ•°ã‚’ä½¿ç”¨ï¼‰
                res = simulate_fn(schedule_dict, mat_dict, edr_dict)
                Lambda = res["Lambda"]
                
                # ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆedr_fit.pyã®é–¢æ•°ã‚’ä½¿ç”¨ï¼‰
                Lambda_smooth = smooth_signal_jax(Lambda, window_size=11)
                
                # å®‰å…¨åˆ¤å®š
                peak_Lambda = float(jnp.max(Lambda_smooth))
                
                if peak_Lambda < safety_threshold:
                    # å®‰å…¨è»Œé“ã¨ã—ã¦æ¡ç”¨
                    safe_lambdas.append(np.array(Lambda_smooth))
                    
                    # Gramè¡Œåˆ—è¨ˆç®—
                    G = compute_gram(Lambda_smooth)
                    safe_grams.append(np.array(G))
                    
                    # æ¡ä»¶è¨˜éŒ²
                    safe_conditions.append({
                        'beta': float(beta),
                        'mu': float(mu),
                        'pN': float(pN),
                        'peak_Lambda': peak_Lambda
                    })
                    
                    safe_count += 1
                
                if verbose and count % 20 == 0:
                    print(f"    é€²æ—: {count}/{n_beta*n_mu*n_pN}, "
                          f"å®‰å…¨è»Œé“: {safe_count}æœ¬")
    
    if verbose:
        print(f"\n  âœ… å®‰å…¨å¤šæ§˜ä½“æ§‹ç¯‰å®Œäº†ï¼")
        print(f"    ç”Ÿæˆè»Œé“: {count}æœ¬")
        print(f"    å®‰å…¨è»Œé“: {safe_count}æœ¬ ({safe_count/count*100:.1f}%)")
        print(f"    Gramè¡Œåˆ—: {safe_count} Ã— [{len(safe_lambdas[0])} Ã— {len(safe_lambdas[0])}]")
    
    return {
        'lambdas': jnp.array(safe_lambdas),
        'grams': jnp.array(safe_grams),
        'conditions': safe_conditions,
        'n_safe': safe_count
    }

# =============================================================================
# Section 4: å®‰å…¨ã‚¹ã‚³ã‚¢è¨ˆç®—
# =============================================================================

@jit
def compute_safety_score(
    Lambda: jnp.ndarray,
    safe_grams: jnp.ndarray,
    weights: Dict[str, float]
):
    """
    å®‰å…¨ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆä½ã„ã»ã©å®‰å…¨ï¼‰
    
    Args:
        Lambda: ãƒ†ã‚¹ãƒˆè»Œé“ [time]
        safe_grams: å®‰å…¨å¤šæ§˜ä½“ã®Gramè¡Œåˆ—ç¾¤ [n_safe, time, time]
        weights: æ­£å‰‡åŒ–ã®é‡ã¿
    
    Returns:
        score: å®‰å…¨ã‚¹ã‚³ã‚¢ï¼ˆä½ã„=å®‰å…¨ã€é«˜ã„=å±é™ºï¼‰
    """
    # ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°é©ç”¨ï¼ˆedr_fit.pyã®é–¢æ•°ã‚’ä½¿ç”¨ï¼‰
    Lambda_smooth = smooth_signal_jax(Lambda, window_size=11)
    
    # ãƒ†ã‚¹ãƒˆã®Gramè¡Œåˆ—
    G_test = compute_gram(Lambda_smooth)
    
    # æœ€ã‚‚è¿‘ã„å®‰å…¨è»Œé“ã¨ã®è·é›¢
    distances = vmap(lambda G_safe: gram_distance(G_test, G_safe))(safe_grams)
    min_dist = jnp.min(distances)
    
    # æ­£å‰‡åŒ–é …
    tv = compute_tv(Lambda_smooth)
    jump = compute_jump_penalty(Lambda_smooth, k=2.5)
    topo = compute_topo_penalty(Lambda_smooth)
    l1 = compute_l1_norm(Lambda_smooth)
    
    # ç·åˆã‚¹ã‚³ã‚¢
    score = (min_dist + 
             weights['tv'] * tv + 
             weights['jump'] * jump + 
             weights['topo'] * topo + 
             weights['l1'] * l1)
    
    return score

# =============================================================================
# Section 5: å¤šæ§˜ä½“ãƒ™ãƒ¼ã‚¹ã®ãƒã‚¤ãƒŠãƒªæå¤±ï¼ˆedr_fit.pyçµ±åˆç‰ˆï¼‰
# =============================================================================

def loss_binary_manifold(
    params,
    exps: List[ExpBinary],
    mat_dict: Dict,
    safe_manifold: Dict,
    simulate_fn=None,
    weights: Optional[Dict[str, float]] = None
):
    """
    å®‰å…¨å¤šæ§˜ä½“ãƒ™ãƒ¼ã‚¹ã®ãƒã‚¤ãƒŠãƒªæå¤±é–¢æ•°
    
    Args:
        params: EDRãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆrawï¼‰
        exps: å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
        mat_dict: ææ–™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        safe_manifold: å®‰å…¨å¤šæ§˜ä½“
        simulate_fn: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–¢æ•°ï¼ˆNoneãªã‚‰edr_fit.pyã®ã‚‚ã®ã‚’ä½¿ç”¨ï¼‰
        weights: æ­£å‰‡åŒ–ã®é‡ã¿
    
    Returns:
        loss: ãƒã‚¤ãƒŠãƒªæå¤±
    """
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé‡ã¿
    if weights is None:
        weights = {
            'tv': 0.1,
            'jump': 0.5,
            'topo': 0.1,
            'l1': 1e-3
        }
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿
    if simulate_fn is None:
        if not EDR_FIT_AVAILABLE:
            raise ImportError("simulate_lambda_jaxãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        simulate_fn = simulate_lambda_jax
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤‰æ›ï¼ˆedr_fit.pyã®é–¢æ•°ã‚’ä½¿ç”¨ï¼‰
    edr_dict = transform_params_jax(params)
    safe_grams = safe_manifold['grams']
    
    total_loss = 0.0
    
    for exp in exps:
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å¤‰æ›ï¼ˆedr_fit.pyã®é–¢æ•°ã‚’ä½¿ç”¨ï¼‰
        schedule_dict = schedule_to_jax_dict(exp.schedule)
        res = simulate_fn(schedule_dict, mat_dict, edr_dict)
        Lambda = res["Lambda"]
        
        # å®‰å…¨ã‚¹ã‚³ã‚¢è¨ˆç®—
        score = compute_safety_score(Lambda, safe_grams, weights)
        
        # é–¾å€¤è¨­å®šï¼ˆèª¿æ•´å¯èƒ½ï¼‰
        safe_threshold = 0.3
        danger_threshold = 0.5
        
        if exp.failed == 1:
            # ç ´æ–­ã‚µãƒ³ãƒ—ãƒ«: ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã¹ãï¼ˆdanger_thresholdä»¥ä¸Šï¼‰
            loss = jnp.maximum(0.0, danger_threshold - score)**2
        else:
            # å®‰å…¨ã‚µãƒ³ãƒ—ãƒ«: ã‚¹ã‚³ã‚¢ãŒä½ã„ã¹ãï¼ˆsafe_thresholdä»¥ä¸‹ï¼‰
            loss = jnp.maximum(0.0, score - safe_threshold)**2
        
        total_loss += loss
    
    return total_loss / len(exps)

# =============================================================================
# Section 6: Phase 1.5Bã¸ã®çµ±åˆï¼ˆåˆ¶ç´„ä»˜ãå¤šæ§˜ä½“æœ€é©åŒ–ï¼‰
# =============================================================================

def phase_15b_manifold_optimization(
    params_init,
    flc_pts_data: Dict,
    exps: List[ExpBinary],
    mat_dict: Dict,
    safe_manifold: Dict,
    simulate_fn=None,
    flc_target: float = None,
    n_steps: int = 500,
    verbose: bool = True
):
    """
    Phase 1.5B: FLCåˆ¶ç´„ä»˜ãå¤šæ§˜ä½“ãƒ™ãƒ¼ã‚¹Binaryæœ€é©åŒ–
    
    Args:
        params_init: åˆæœŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        flc_pts_data: FLCãƒ‡ãƒ¼ã‚¿
        exps: ãƒã‚¤ãƒŠãƒªå®Ÿé¨“ãƒ‡ãƒ¼ã‚¿
        mat_dict: ææ–™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        safe_manifold: å®‰å…¨å¤šæ§˜ä½“
        simulate_fn: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–¢æ•°ï¼ˆNoneãªã‚‰edr_fit.pyã®ã‚‚ã®ã‚’ä½¿ç”¨ï¼‰
        flc_target: FLCç›®æ¨™å€¤ï¼ˆNoneãªã‚‰ç¾åœ¨å€¤ã‚’ä½¿ç”¨ï¼‰
        n_steps: ã‚¹ãƒ†ãƒƒãƒ—æ•°
        verbose: é€²æ—è¡¨ç¤º
    
    Returns:
        params_final: æœ€é©åŒ–å¾Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        history: æœ€é©åŒ–å±¥æ­´
    """
    if not OPTAX_AVAILABLE:
        raise ImportError("optaxãŒå¿…è¦ã§ã™: pip install optax")
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿
    if simulate_fn is None:
        if not EDR_FIT_AVAILABLE:
            raise ImportError("simulate_lambda_jaxãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        simulate_fn = simulate_lambda_jax
    
    # FLCç›®æ¨™å€¤ã®è¨­å®š
    if flc_target is None:
        # ç¾åœ¨ã®FLCæå¤±ã‚’ç›®æ¨™å€¤ã¨ã—ã¦è¨­å®š
        flc_target = float(loss_flc_true_jax(params_init, flc_pts_data, mat_dict))
    
    if verbose:
        print("\n" + "="*60)
        print(" ğŸ‚ Phase 1.5B: åˆ¶ç´„ä»˜ãå¤šæ§˜ä½“æœ€é©åŒ–")
        print("="*60)
        print(f"  FLCåˆ¶ç´„: < {flc_target * 1.03:.6f} (3%è¨±å®¹)")
        print(f"  ç›®çš„: Binaryæœ€å°åŒ–ï¼ˆå¤šæ§˜ä½“ãƒ™ãƒ¼ã‚¹ï¼‰")
        print(f"  ã‚¹ãƒ†ãƒƒãƒ—æ•°: {n_steps}")
    
    # æ­£å‰‡åŒ–ã®é‡ã¿
    manifold_weights = {
        'tv': 0.1,
        'jump': 0.5,
        'topo': 0.1,
        'l1': 1e-3
    }
    
    # åˆ¶ç´„ä»˜ãæå¤±é–¢æ•°
    def loss_constrained(params):
        # FLCæå¤±ï¼ˆedr_fit.pyã®é–¢æ•°ã‚’ä½¿ç”¨ï¼‰
        flc_loss = loss_flc_true_jax(params, flc_pts_data, mat_dict)
        
        # å¤šæ§˜ä½“ãƒ™ãƒ¼ã‚¹ã®ãƒã‚¤ãƒŠãƒªæå¤±
        bin_loss = loss_binary_manifold(
            params, exps, mat_dict, safe_manifold, 
            simulate_fn, manifold_weights
        )
        
        # FLCé–¾å€¤
        flc_threshold = flc_target * 1.03
        
        # å‹•çš„é‡ã¿ä»˜ã‘
        flc_margin = (flc_loss - flc_threshold) / (flc_threshold * 0.01)
        w_transition = jax.nn.sigmoid(flc_margin * 5.0)
        w_flc = 0.1 + 0.8 * w_transition
        w_bin = 1.0 - w_flc
        
        return w_flc * flc_loss + w_bin * bin_loss, flc_loss, bin_loss
    
    # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶
    optimizer = optax.chain(
        optax.clip_by_global_norm(0.3),
        optax.adamw(learning_rate=1e-3, weight_decay=1e-5)
    )
    
    opt_state = optimizer.init(params_init)
    params = params_init
    
    # å‹¾é…é–¢æ•°
    grad_fn = jax.grad(lambda p: loss_constrained(p)[0])
    
    # å±¥æ­´
    history = {
        'total': [],
        'flc': [],
        'binary': []
    }
    
    # æœ€é©åŒ–ãƒ«ãƒ¼ãƒ—
    for step in range(n_steps):
        # å‹¾é…è¨ˆç®—
        grads = grad_fn(params)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°
        updates, opt_state = optimizer.update(grads, opt_state, params)
        params = optax.apply_updates(params, updates)
        
        # é€²æ—è¡¨ç¤º
        if step % 100 == 0 and verbose:
            total_loss, flc_loss, bin_loss = loss_constrained(params)
            history['total'].append(float(total_loss))
            history['flc'].append(float(flc_loss))
            history['binary'].append(float(bin_loss))
            
            print(f"  Step {step:3d}: Total = {float(total_loss):.6f} "
                  f"(FLC: {float(flc_loss):.6f}, Binary: {float(bin_loss):.6f})")
    
    if verbose:
        print(f"\n  âœ… Phase 1.5Bå®Œäº†ï¼")
    
    return params, history

# =============================================================================
# Section 8: å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆPhase 0 â†’ å¤šæ§˜ä½“ â†’ Binaryæœ€é©åŒ–ï¼‰
# =============================================================================

def marie_antoinette_pipeline(
    mat_dict: Dict,
    exps: Optional[List[ExpBinary]] = None,
    flc_pts_data: Optional[Dict] = None,
    use_phase0: bool = True,
    phase0_steps: int = 300,
    manifold_params: Optional[Dict] = None,
    phase15b_steps: int = 500,
    verbose: bool = True
):
    """
    Operation Marie Antoinette å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    
    Phase 0ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰: æ•™å¸«ãªã—ç‰©ç†åˆ¶ç´„å­¦ç¿’
      â†“
    å®‰å…¨å¤šæ§˜ä½“æ§‹ç¯‰: å¤§é‡ã®å®‰å…¨è»Œé“ç”Ÿæˆ
      â†“
    Phase 1.5Bï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰: FLCåˆ¶ç´„ä»˜ãBinaryæœ€é©åŒ–
    
    Args:
        mat_dict: ææ–™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        exps: ãƒã‚¤ãƒŠãƒªå®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ï¼ˆPhase 1.5Bç”¨ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        flc_pts_data: FLCãƒ‡ãƒ¼ã‚¿ï¼ˆPhase 1.5Bç”¨ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        use_phase0: Phase 0ã‚’å®Ÿè¡Œã™ã‚‹ã‹
        phase0_steps: Phase 0ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°
        manifold_params: å¤šæ§˜ä½“æ§‹ç¯‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆn_beta, n_mu, n_pNï¼‰
        phase15b_steps: Phase 1.5Bã®ã‚¹ãƒ†ãƒƒãƒ—æ•°
        verbose: é€²æ—è¡¨ç¤º
    
    Returns:
        results: {
            'params': æœ€çµ‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿,
            'safe_manifold': å®‰å…¨å¤šæ§˜ä½“,
            'phase0_history': Phase 0å±¥æ­´,
            'phase15b_history': Phase 1.5Bå±¥æ­´
        }
    """
    if verbose:
        print("="*80)
        print(" ğŸ‚ Operation Marie Antoinette - Complete Pipeline")
        print("="*80)
        print("\nã€Œãƒ‡ãƒ¼ã‚¿ãŒãªã„ãªã‚‰ä½œã‚Œã°ã„ã„ã˜ã‚ƒãªã„ï¼ã€")
        print("  Phase 0: æ•™å¸«ãªã—å­¦ç¿’ â†’ å¤šæ§˜ä½“æ§‹ç¯‰ â†’ Binaryæœ€é©åŒ–\n")
    
    results = {}
    
    # ===========================
    # Phase 0: æ•™å¸«ãªã—å­¦ç¿’
    # ===========================
    if use_phase0:
        params_phase0, phase0_history = phase0_unsupervised_learning(
            mat_dict,
            n_steps=phase0_steps,
            verbose=verbose
        )
        edr_dict = transform_params_jax(params_phase0)
        results['phase0_history'] = phase0_history
        results['params_phase0'] = params_phase0
        
        if verbose:
            print(f"\nâœ… Phase 0å®Œäº†ï¼ç‰©ç†çš„ã«å¦¥å½“ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç²å¾—")
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä½¿ç”¨
        params_phase0 = init_edr_params_jax()
        edr_dict = transform_params_jax(params_phase0)
        results['phase0_history'] = None
        
        if verbose:
            print(f"\nâ­ï¸  Phase 0ã‚¹ã‚­ãƒƒãƒ—: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä½¿ç”¨")
    
    # ===========================
    # å®‰å…¨å¤šæ§˜ä½“æ§‹ç¯‰
    # ===========================
    if manifold_params is None:
        manifold_params = {
            'n_beta': 15,
            'n_mu': 5,
            'n_pN': 5
        }
    
    if verbose:
        print(f"\n{'='*60}")
        print(" å®‰å…¨å¤šæ§˜ä½“æ§‹ç¯‰")
        print(f"{'='*60}")
    
    safe_manifold = build_safe_manifold(
        mat_dict, edr_dict,
        n_beta=manifold_params['n_beta'],
        n_mu=manifold_params['n_mu'],
        n_pN=manifold_params['n_pN'],
        duration=0.6,
        safety_margin=0.85,
        verbose=verbose
    )
    
    results['safe_manifold'] = safe_manifold
    results['params_manifold'] = params_phase0  # å¤šæ§˜ä½“æ§‹ç¯‰æ™‚ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    
    if verbose:
        print(f"\nâœ… å®‰å…¨å¤šæ§˜ä½“æ§‹ç¯‰å®Œäº†ï¼{safe_manifold['n_safe']}æœ¬ã®å®‰å…¨è»Œé“")
    
    # ===========================
    # Phase 1.5B: Binaryæœ€é©åŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    # ===========================
    if exps is not None and flc_pts_data is not None:
        if verbose:
            print(f"\n{'='*60}")
            print(" Phase 1.5B: åˆ¶ç´„ä»˜ãBinaryæœ€é©åŒ–")
            print(f"{'='*60}")
        
        params_final, phase15b_history = phase_15b_manifold_optimization(
            params_phase0,
            flc_pts_data,
            exps,
            mat_dict,
            safe_manifold,
            n_steps=phase15b_steps,
            verbose=verbose
        )
        
        results['params_final'] = params_final
        results['phase15b_history'] = phase15b_history
        
        if verbose:
            print(f"\nâœ… Phase 1.5Bå®Œäº†ï¼Binaryæœ€é©åŒ–æˆåŠŸ")
    else:
        results['params_final'] = params_phase0
        results['phase15b_history'] = None
        
        if verbose:
            print(f"\nâ­ï¸  Phase 1.5Bã‚¹ã‚­ãƒƒãƒ—: å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ãªã—")
    
    # ===========================
    # ã‚µãƒãƒªãƒ¼
    # ===========================
    if verbose:
        print(f"\n{'='*80}")
        print(" ğŸ‚ Pipeline Complete!")
        print(f"{'='*80}")
        
        if use_phase0:
            print(f"\nâœ… Phase 0: Physics Loss = {results['phase0_history'][-1]:.6f}")
        
        print(f"âœ… å®‰å…¨å¤šæ§˜ä½“: {safe_manifold['n_safe']}æœ¬ã®è»Œé“")
        
        if results['phase15b_history'] is not None:
            print(f"âœ… Phase 1.5B: Binaryæœ€é©åŒ–å®Œäº†")
            print(f"   FLC Loss: {results['phase15b_history']['flc'][-1]:.6f}")
            print(f"   Binary Loss: {results['phase15b_history']['binary'][-1]:.6f}")
        
        print(f"\nğŸ‰ Operation Marie Antoinetteå¤§æˆåŠŸï¼")
    
    return results

# =============================================================================
# Section 9: ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆedr_fit.pyçµ±åˆç‰ˆï¼‰
# =============================================================================

def visualize_safe_manifold(safe_manifold: Dict, output_path: str = None):
    """å®‰å…¨å¤šæ§˜ä½“ã®å¯è¦–åŒ–"""
    import matplotlib.pyplot as plt
    
    lambdas = safe_manifold['lambdas']
    conditions = safe_manifold['conditions']
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # (1) å…¨è»Œé“ãƒ—ãƒ­ãƒƒãƒˆ
    ax = axes[0, 0]
    for i, lam in enumerate(lambdas[:50]):  # æœ€åˆã®50æœ¬
        ax.plot(lam, alpha=0.3, linewidth=0.5)
    ax.set_xlabel('Time Step')
    ax.set_ylabel('Î›(t)')
    ax.set_title(f'Safe Trajectories (n={len(lambdas)})')
    ax.grid(True, alpha=0.3)
    
    # (2) Î²ã”ã¨ã®åˆ†å¸ƒ
    ax = axes[0, 1]
    betas = [c['beta'] for c in conditions]
    peaks = [c['peak_Lambda'] for c in conditions]
    sc = ax.scatter(betas, peaks, c=peaks, cmap='viridis', alpha=0.6)
    ax.set_xlabel('Î² (path ratio)')
    ax.set_ylabel('Peak Î›')
    ax.set_title('Peak Î› vs Î²')
    ax.grid(True, alpha=0.3)
    plt.colorbar(sc, ax=ax, label='Peak Î›')
    
    # (3) Gramè¡Œåˆ—ã®ã‚µãƒ³ãƒ—ãƒ«
    ax = axes[1, 0]
    G_sample = safe_manifold['grams'][0]
    im = ax.imshow(G_sample, cmap='RdBu_r', aspect='auto')
    ax.set_xlabel('Time')
    ax.set_ylabel('Time')
    ax.set_title('Sample Gram Matrix')
    plt.colorbar(im, ax=ax)
    
    # (4) æ¡ä»¶åˆ†å¸ƒ
    ax = axes[1, 1]
    mus = [c['mu'] for c in conditions]
    pNs = [c['pN']/1e6 for c in conditions]  # MPa
    sc = ax.scatter(mus, pNs, c=peaks, cmap='viridis', alpha=0.6)
    ax.set_xlabel('Î¼ (friction)')
    ax.set_ylabel('pN (MPa)')
    ax.set_title('Condition Space Coverage')
    ax.grid(True, alpha=0.3)
    plt.colorbar(sc, ax=ax, label='Peak Î›')
    
    plt.tight_layout()
    
    if output_path:
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"  å¯è¦–åŒ–ä¿å­˜: {output_path}")
    
    plt.show()
    
    return fig

def analyze_safety_scores(
    exps: List[ExpBinary],
    mat_dict: Dict,
    edr_dict: Dict,
    safe_manifold: Dict,
    simulate_fn=None,
    weights: Optional[Dict[str, float]] = None
):
    """
    å…¨å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã®å®‰å…¨ã‚¹ã‚³ã‚¢åˆ†æ
    """
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé‡ã¿
    if weights is None:
        weights = {
            'tv': 0.1,
            'jump': 0.5,
            'topo': 0.1,
            'l1': 1e-3
        }
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿
    if simulate_fn is None:
        if not EDR_FIT_AVAILABLE:
            raise ImportError("simulate_lambda_jaxãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        simulate_fn = simulate_lambda_jax
    
    print("\n" + "="*60)
    print(" ğŸ‚ Safety Score Analysis")
    print("="*60)
    
    safe_grams = safe_manifold['grams']
    
    for i, exp in enumerate(exps):
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å¤‰æ›ï¼ˆedr_fit.pyã®é–¢æ•°ã‚’ä½¿ç”¨ï¼‰
        schedule_dict = schedule_to_jax_dict(exp.schedule)
        res = simulate_fn(schedule_dict, mat_dict, edr_dict)
        Lambda = res["Lambda"]
        
        # å®‰å…¨ã‚¹ã‚³ã‚¢è¨ˆç®—
        score = float(compute_safety_score(Lambda, safe_grams, weights))
        
        # å„æˆåˆ†ã®å¯„ä¸
        Lambda_smooth = smooth_signal_jax(Lambda, window_size=11)
        G_test = compute_gram(Lambda_smooth)
        distances = [float(gram_distance(G_test, G_safe)) for G_safe in safe_grams]
        min_dist = min(distances)
        
        tv = float(compute_tv(Lambda_smooth))
        jump = float(compute_jump_penalty(Lambda_smooth))
        topo = float(compute_topo_penalty(Lambda_smooth))
        l1 = float(compute_l1_norm(Lambda_smooth))
        
        status = "ç ´æ–­" if exp.failed == 1 else "å®‰å…¨"
        
        print(f"\nExp{i} ({exp.label}, {status}):")
        print(f"  Total Score: {score:.4f}")
        print(f"    Gramè·é›¢: {min_dist:.4f}")
        print(f"    TV      : {tv:.4f} (Ã— {weights['tv']:.2f})")
        print(f"    Jump    : {jump:.4f} (Ã— {weights['jump']:.2f})")
        print(f"    Topo    : {topo:.4f} (Ã— {weights['topo']:.2f})")
        print(f"    L1      : {l1:.4f} (Ã— {weights['l1']:.4f})")

# =============================================================================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œä¾‹ï¼ˆå®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç‰ˆï¼‰
# =============================================================================

if __name__ == "__main__":
    print("="*80)
    print(" ğŸ‚ Operation Marie Antoinette v2.0")
    print(" ã€Œãƒ‡ãƒ¼ã‚¿ãŒãªã„ãªã‚‰ä½œã‚Œã°ã„ã„ã˜ã‚ƒãªã„ï¼ã€")
    print(" ï¼ˆedr_fit.pyå®Œå…¨çµ±åˆç‰ˆ + Phase 0ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼‰")
    print("="*80)
    
    print("\né€†å•é¡ŒÃ—å¤šæ§˜ä½“å­¦ç¿’ã«ã‚ˆã‚‹ç ´æ–­åˆ¤å®šã‚·ã‚¹ãƒ†ãƒ ")
    print("  - Phase 0: æ•™å¸«ãªã—ç‰©ç†åˆ¶ç´„å­¦ç¿’")
    print("  - å®‰å…¨å¤šæ§˜ä½“ã®è‡ªå‹•æ§‹ç¯‰")
    print("  - Gramè¡Œåˆ—ãƒ™ãƒ¼ã‚¹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜")
    print("  - ç‰©ç†çš„ç•°å¸¸æ¤œå‡ºï¼ˆTV, Jump, Topoæ­£å‰‡åŒ–ï¼‰")
    print("  - ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆé‹ç”¨å¯èƒ½")
    print("  âœ… edr_fit.pyã®å…¨æ©Ÿèƒ½ã‚’æ´»ç”¨")
    
    if EDR_FIT_AVAILABLE:
        print("\nâœ… edr_fit.pyçµ±åˆå®Œäº†")
        print("  åˆ©ç”¨å¯èƒ½ãªæ©Ÿèƒ½:")
        print("    - simulate_lambda_jax")
        print("    - smooth_signal_jax")
        print("    - triax_from_path_jax")
        print("    - schedule_to_jax_dict")
        print("    - mat_to_jax_dict")
        print("    - loss_flc_true_jax")
        print("    - Phase 0æ•™å¸«ãªã—å­¦ç¿’")
        print("    - ãã®ä»–å…¨æ©Ÿèƒ½")
        
        print("\n" + "="*60)
        print(" ãƒ‡ãƒ¢å®Ÿè¡Œ")
        print("="*60)
        
        # ææ–™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        from edr_fit import generate_demo_experiments, generate_demo_flc
        
        mat = MaterialParams()
        mat_dict = mat_to_jax_dict(mat)
        
        # ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿
        exps = generate_demo_experiments()
        flc_data_list = generate_demo_flc()
        
        # FLCãƒ‡ãƒ¼ã‚¿ã‚’dictåŒ–
        flc_pts_data = {
            'path_ratios': jnp.array([p.path_ratio for p in flc_data_list]),
            'major_limits': jnp.array([p.major_limit for p in flc_data_list]),
            'minor_limits': jnp.array([p.minor_limit for p in flc_data_list])
        }
        
        print(f"\nâœ“ Material params: OK")
        print(f"âœ“ Binary experiments: {len(exps)}")
        print(f"âœ“ FLC points: {len(flc_data_list)}")
        
        # å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
        results = marie_antoinette_pipeline(
            mat_dict=mat_dict,
            exps=exps,
            flc_pts_data=flc_pts_data,
            use_phase0=True,
            phase0_steps=300,
            manifold_params={'n_beta': 15, 'n_mu': 5, 'n_pN': 5},
            phase15b_steps=500,
            verbose=True
        )
        
        # çµæœå¯è¦–åŒ–
        print("\n" + "="*60)
        print(" çµæœå¯è¦–åŒ–")
        print("="*60)
        
        visualize_safe_manifold(
            results['safe_manifold'],
            output_path='safe_manifold_demo.png'
        )
        
        # å®‰å…¨ã‚¹ã‚³ã‚¢åˆ†æ
        edr_dict_final = transform_params_jax(results['params_final'])
        
        analyze_safety_scores(
            exps, mat_dict, edr_dict_final,
            results['safe_manifold']
        )
        
        print("\n" + "="*80)
        print(" ğŸ‰ ãƒ‡ãƒ¢å®Ÿè¡Œå®Œäº†ï¼")
        print("="*80)
        
    else:
        print("\nâš ï¸  edr_fit.pyãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("  åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«edr_fit.pyã‚’é…ç½®ã—ã¦ãã ã•ã„")
