"""
=============================================================================
Operation Marie Antoinette: Inverse Problem Data Augmentation
"ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãªã‚‰ä½œã‚Œã°ã„ã„ã˜ã‚ƒãªã„ï¼"

é€†å•é¡ŒÃ—å¤šæ§˜ä½“å­¦ç¿’Ã—ã‚¤ãƒ™ãƒ³ãƒˆã‚°ãƒ©ãƒ ã«ã‚ˆã‚‹ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆç ´æ–­åˆ¤å®š
=============================================================================
"""

import jax
import jax.numpy as jnp
from jax import jit, vmap
import numpy as np
from typing import List, Dict, Tuple
from dataclasses import dataclass

# =============================================================================
# Section 1: Gramè¡Œåˆ—ã¨ã‚¤ãƒ™ãƒ³ãƒˆè¡¨ç¾
# =============================================================================

@jit
def compute_gram(x):
    """
    Gramè¡Œåˆ—è¨ˆç®—ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«ä¸å¤‰ç‰ˆï¼‰
    
    Args:
        x: [time] ã¾ãŸã¯ [batch, time]
    Returns:
        Gramè¡Œåˆ— [time, time]
    """
    # 0-meanåŒ–
    x_centered = x - jnp.mean(x, axis=-1, keepdims=True)
    # L2æ­£è¦åŒ–
    x_norm = x_centered / (jnp.linalg.norm(x_centered, axis=-1, keepdims=True) + 1e-8)
    # Gramè¡Œåˆ—
    if x_norm.ndim == 1:
        return jnp.outer(x_norm, x_norm)
    else:
        return x_norm @ x_norm.T

@jit
def gram_distance(G1, G2):
    """2ã¤ã®Gramè¡Œåˆ—é–“ã®è·é›¢"""
    return jnp.sum((G1 - G2)**2)

# =============================================================================
# Section 2: æ­£å‰‡åŒ–é …ï¼ˆç‰©ç†çš„ç•°å¸¸æ¤œå‡ºï¼‰
# =============================================================================

@jit
def compute_tv(Lambda):
    """
    Total Variationï¼ˆå…¨å¤‰å‹•ï¼‰
    æ™‚é–“æ–¹å‘ã®æ€¥æ¿€ãªå¤‰åŒ–ã‚’æ¤œå‡º
    """
    if Lambda.ndim == 1:
        return jnp.sum(jnp.abs(jnp.diff(Lambda)))
    else:
        # [paths, time]
        tv_time = jnp.sum(jnp.abs(jnp.diff(Lambda, axis=1)))
        tv_path = jnp.sum(jnp.abs(jnp.diff(Lambda, axis=0)))
        return tv_time + tv_path

@jit
def compute_jump_penalty(Lambda, k=2.5):
    """
    Jumpæ­£å‰‡åŒ–ï¼šå¤–ã‚Œå€¤çš„ãªæ€¥å¤‰ã‚’æ¤œå‡º
    
    Args:
        Lambda: [time] ã¾ãŸã¯ [paths, time]
        k: æ¨™æº–åå·®ã®ä½•å€ã‚’é–¾å€¤ã¨ã™ã‚‹ã‹
    """
    if Lambda.ndim == 1:
        d = jnp.abs(jnp.diff(Lambda))
        threshold = jnp.mean(d) + k * jnp.std(d)
        return jnp.sum(jnp.maximum(0.0, d - threshold))
    else:
        # [paths, time-1]
        d = jnp.abs(jnp.diff(Lambda, axis=1))
        threshold = jnp.mean(d, axis=1, keepdims=True) + k * jnp.std(d, axis=1, keepdims=True)
        return jnp.sum(jnp.maximum(0.0, d - threshold))

@jit
def compute_topo_penalty(Lambda):
    """
    ä½ç›¸é€£ç¶šæ€§æ­£å‰‡åŒ–
    Phaseé·ç§»ã®æ»‘ã‚‰ã‹ã•ã‚’è©•ä¾¡
    """
    if Lambda.ndim == 1:
        # phase_k = atan2(Lambda[k+1], Lambda[k])
        phase = jnp.arctan2(Lambda[1:], Lambda[:-1])
        # ä½ç›¸å·®
        dphase = jnp.diff(phase)
        # [-Ï€, Ï€]ã«æ­£è¦åŒ–
        dphase = (dphase + jnp.pi) % (2 * jnp.pi) - jnp.pi
        return jnp.sum(dphase**2)
    else:
        # [paths, time-1]
        phase = jnp.arctan2(Lambda[:, 1:], Lambda[:, :-1])
        dphase = jnp.diff(phase, axis=1)
        dphase = (dphase + jnp.pi) % (2 * jnp.pi) - jnp.pi
        return jnp.sum(dphase**2)

@jit
def compute_l1_norm(Lambda):
    """L1æ­£å‰‡åŒ–ï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ä¿ƒé€²ï¼‰"""
    return jnp.sum(jnp.abs(Lambda))

# =============================================================================
# Section 3: å®‰å…¨å¤šæ§˜ä½“ã®æ§‹ç¯‰
# =============================================================================

def build_safe_manifold(
    mat_dict: Dict,
    edr_dict: Dict,
    simulate_fn,
    n_beta: int = 15,
    n_mu: int = 5,
    n_pN: int = 5,
    safety_margin: float = 0.85,
    verbose: bool = True
):
    """
    å®‰å…¨ãªÎ›(t)è»Œé“ã‚’å¤§é‡ç”Ÿæˆã—ã¦å¤šæ§˜ä½“ã‚’æ§‹ç¯‰
    
    Args:
        mat_dict: ææ–™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆJAX dictï¼‰
        edr_dict: EDRãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆJAX dictï¼‰
        simulate_fn: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–¢æ•°
        n_beta: Î²æ–¹å‘ã®ã‚µãƒ³ãƒ—ãƒ«æ•°
        n_mu: æ‘©æ“¦ä¿‚æ•°ã®ã‚µãƒ³ãƒ—ãƒ«æ•°
        n_pN: æ¥è§¦åœ§ã®ã‚µãƒ³ãƒ—ãƒ«æ•°
        safety_margin: Lambda_crit * safety_margin ä»¥ä¸‹ã‚’å®‰å…¨ã¨åˆ¤å®š
        verbose: é€²æ—è¡¨ç¤º
    
    Returns:
        safe_manifold: {
            'lambdas': [n_safe, time],
            'grams': [n_safe, time, time],
            'conditions': [n_safe] ã®æ¡ä»¶ãƒªã‚¹ãƒˆ
        }
    """
    if verbose:
        print("\n" + "="*60)
        print(" ğŸ‚ Operation Marie Antoinette: å®‰å…¨å¤šæ§˜ä½“æ§‹ç¯‰")
        print("="*60)
        print(f"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“æ¢ç´¢:")
        print(f"    Î²: {n_beta}ç‚¹")
        print(f"    Î¼: {n_mu}ç‚¹")
        print(f"    pN: {n_pN}ç‚¹")
        print(f"    åˆè¨ˆ: {n_beta * n_mu * n_pN}è»Œé“ã‚’ç”Ÿæˆ")
    
    safe_lambdas = []
    safe_grams = []
    safe_conditions = []
    
    Lambda_crit = edr_dict['Lambda_crit']
    safety_threshold = Lambda_crit * safety_margin
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚°ãƒªãƒƒãƒ‰
    betas = jnp.linspace(-0.7, 0.7, n_beta)
    mus = jnp.linspace(0.05, 0.10, n_mu)
    pNs = jnp.linspace(150e6, 250e6, n_pN)
    
    count = 0
    safe_count = 0
    
    for beta in betas:
        for mu in mus:
            for pN in pNs:
                count += 1
                
                # å®‰å…¨ãªã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç”Ÿæˆï¼ˆä½è² è·ï¼‰
                duration = 0.8
                major_rate = 0.4  # ä½ã²ãšã¿é€Ÿåº¦
                dt = 1e-3
                N = int(duration/dt) + 1
                t = jnp.linspace(0, duration, N)
                epsM = major_rate * t
                epsm = beta * epsM
                
                # ä¸‰è»¸åº¦è¨ˆç®—
                from edr_fit_fixed import triax_from_path_jax
                triax_val = triax_from_path_jax(beta)
                
                schedule_dict = {
                    't': t,
                    'eps_maj': epsM,
                    'eps_min': epsm,
                    'triax': jnp.full(N, triax_val),
                    'mu': jnp.full(N, float(mu)),
                    'pN': jnp.full(N, float(pN)),
                    'vslip': jnp.full(N, 0.015),
                    'htc': jnp.full(N, 8000.0),
                    'Tdie': jnp.full(N, 293.15),
                    'contact': jnp.full(N, 1.0),
                    'T0': 293.15
                }
                
                # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
                res = simulate_fn(schedule_dict, mat_dict, edr_dict)
                Lambda = res["Lambda"]
                
                # å®‰å…¨åˆ¤å®š
                peak_Lambda = float(jnp.max(Lambda))
                
                if peak_Lambda < safety_threshold:
                    # å®‰å…¨è»Œé“ã¨ã—ã¦æ¡ç”¨
                    safe_lambdas.append(np.array(Lambda))
                    
                    # Gramè¡Œåˆ—è¨ˆç®—
                    G = compute_gram(Lambda)
                    safe_grams.append(np.array(G))
                    
                    # æ¡ä»¶è¨˜éŒ²
                    safe_conditions.append({
                        'beta': float(beta),
                        'mu': float(mu),
                        'pN': float(pN),
                        'peak_Lambda': peak_Lambda
                    })
                    
                    safe_count += 1
                
                if verbose and count % 20 == 0:
                    print(f"    é€²æ—: {count}/{n_beta*n_mu*n_pN}, "
                          f"å®‰å…¨è»Œé“: {safe_count}æœ¬")
    
    if verbose:
        print(f"\n  âœ… å®‰å…¨å¤šæ§˜ä½“æ§‹ç¯‰å®Œäº†ï¼")
        print(f"    ç”Ÿæˆè»Œé“: {count}æœ¬")
        print(f"    å®‰å…¨è»Œé“: {safe_count}æœ¬ ({safe_count/count*100:.1f}%)")
        print(f"    Gramè¡Œåˆ—: {safe_count} Ã— [{len(safe_lambdas[0])} Ã— {len(safe_lambdas[0])}]")
    
    return {
        'lambdas': jnp.array(safe_lambdas),
        'grams': jnp.array(safe_grams),
        'conditions': safe_conditions,
        'n_safe': safe_count
    }

# =============================================================================
# Section 4: å®‰å…¨ã‚¹ã‚³ã‚¢è¨ˆç®—
# =============================================================================

@jit
def compute_safety_score(
    Lambda: jnp.ndarray,
    safe_grams: jnp.ndarray,
    weights: Dict[str, float]
):
    """
    å®‰å…¨ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆä½ã„ã»ã©å®‰å…¨ï¼‰
    
    Args:
        Lambda: ãƒ†ã‚¹ãƒˆè»Œé“ [time]
        safe_grams: å®‰å…¨å¤šæ§˜ä½“ã®Gramè¡Œåˆ—ç¾¤ [n_safe, time, time]
        weights: æ­£å‰‡åŒ–ã®é‡ã¿
    
    Returns:
        score: å®‰å…¨ã‚¹ã‚³ã‚¢ï¼ˆä½ã„=å®‰å…¨ã€é«˜ã„=å±é™ºï¼‰
    """
    # ãƒ†ã‚¹ãƒˆã®Gramè¡Œåˆ—
    G_test = compute_gram(Lambda)
    
    # æœ€ã‚‚è¿‘ã„å®‰å…¨è»Œé“ã¨ã®è·é›¢
    distances = vmap(lambda G_safe: gram_distance(G_test, G_safe))(safe_grams)
    min_dist = jnp.min(distances)
    
    # æ­£å‰‡åŒ–é …
    tv = compute_tv(Lambda)
    jump = compute_jump_penalty(Lambda, k=2.5)
    topo = compute_topo_penalty(Lambda)
    l1 = compute_l1_norm(Lambda)
    
    # ç·åˆã‚¹ã‚³ã‚¢
    score = (min_dist + 
             weights['tv'] * tv + 
             weights['jump'] * jump + 
             weights['topo'] * topo + 
             weights['l1'] * l1)
    
    return score

# =============================================================================
# Section 5: å¤šæ§˜ä½“ãƒ™ãƒ¼ã‚¹ã®ãƒã‚¤ãƒŠãƒªæå¤±
# =============================================================================

def loss_binary_manifold(
    params,
    exps,
    mat_dict,
    safe_manifold: Dict,
    simulate_fn,
    weights: Dict[str, float]
):
    """
    å®‰å…¨å¤šæ§˜ä½“ãƒ™ãƒ¼ã‚¹ã®ãƒã‚¤ãƒŠãƒªæå¤±é–¢æ•°
    
    Args:
        params: EDRãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆrawï¼‰
        exps: å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
        mat_dict: ææ–™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        safe_manifold: å®‰å…¨å¤šæ§˜ä½“
        simulate_fn: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–¢æ•°
        weights: æ­£å‰‡åŒ–ã®é‡ã¿
    
    Returns:
        loss: ãƒã‚¤ãƒŠãƒªæå¤±
    """
    from edr_fit_fixed import transform_params_jax, schedule_to_jax_dict
    
    edr_dict = transform_params_jax(params)
    safe_grams = safe_manifold['grams']
    
    total_loss = 0.0
    
    for exp in exps:
        schedule_dict = schedule_to_jax_dict(exp.schedule)
        res = simulate_fn(schedule_dict, mat_dict, edr_dict)
        Lambda = res["Lambda"]
        
        # å®‰å…¨ã‚¹ã‚³ã‚¢è¨ˆç®—
        score = compute_safety_score(Lambda, safe_grams, weights)
        
        # é–¾å€¤è¨­å®šï¼ˆèª¿æ•´å¯èƒ½ï¼‰
        safe_threshold = 0.3
        danger_threshold = 0.5
        
        if exp.failed == 1:
            # ç ´æ–­ã‚µãƒ³ãƒ—ãƒ«: ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã¹ãï¼ˆdanger_thresholdä»¥ä¸Šï¼‰
            loss = jnp.maximum(0.0, danger_threshold - score)**2
        else:
            # å®‰å…¨ã‚µãƒ³ãƒ—ãƒ«: ã‚¹ã‚³ã‚¢ãŒä½ã„ã¹ãï¼ˆsafe_thresholdä»¥ä¸‹ï¼‰
            loss = jnp.maximum(0.0, score - safe_threshold)**2
        
        total_loss += loss
    
    return total_loss / len(exps)

# =============================================================================
# Section 6: Phase 1.5Bã¸ã®çµ±åˆï¼ˆåˆ¶ç´„ä»˜ãå¤šæ§˜ä½“æœ€é©åŒ–ï¼‰
# =============================================================================

def phase_15b_manifold_optimization(
    params_init,
    flc_pts_data,
    exps,
    mat_dict,
    safe_manifold: Dict,
    simulate_fn,
    flc_target: float,
    n_steps: int = 500,
    verbose: bool = True
):
    """
    Phase 1.5B: FLCåˆ¶ç´„ä»˜ãå¤šæ§˜ä½“ãƒ™ãƒ¼ã‚¹Binaryæœ€é©åŒ–
    
    Args:
        params_init: åˆæœŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        flc_pts_data: FLCãƒ‡ãƒ¼ã‚¿
        exps: ãƒã‚¤ãƒŠãƒªå®Ÿé¨“ãƒ‡ãƒ¼ã‚¿
        mat_dict: ææ–™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        safe_manifold: å®‰å…¨å¤šæ§˜ä½“
        simulate_fn: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–¢æ•°
        flc_target: FLCç›®æ¨™å€¤
        n_steps: ã‚¹ãƒ†ãƒƒãƒ—æ•°
        verbose: é€²æ—è¡¨ç¤º
    
    Returns:
        params_final: æœ€é©åŒ–å¾Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        history: æœ€é©åŒ–å±¥æ­´
    """
    import optax
    from edr_fit_fixed import loss_flc_true_jax
    
    if verbose:
        print("\n" + "="*60)
        print(" ğŸ‚ Phase 1.5B: åˆ¶ç´„ä»˜ãå¤šæ§˜ä½“æœ€é©åŒ–")
        print("="*60)
        print(f"  FLCåˆ¶ç´„: < {flc_target * 1.03:.6f} (3%è¨±å®¹)")
        print(f"  ç›®çš„: Binaryæœ€å°åŒ–ï¼ˆå¤šæ§˜ä½“ãƒ™ãƒ¼ã‚¹ï¼‰")
        print(f"  ã‚¹ãƒ†ãƒƒãƒ—æ•°: {n_steps}")
    
    # æ­£å‰‡åŒ–ã®é‡ã¿
    manifold_weights = {
        'tv': 0.1,
        'jump': 0.5,
        'topo': 0.1,
        'l1': 1e-3
    }
    
    # åˆ¶ç´„ä»˜ãæå¤±é–¢æ•°
    def loss_constrained(params):
        flc_loss = loss_flc_true_jax(params, flc_pts_data, mat_dict)
        bin_loss = loss_binary_manifold(
            params, exps, mat_dict, safe_manifold, 
            simulate_fn, manifold_weights
        )
        
        # FLCé–¾å€¤
        flc_threshold = flc_target * 1.03
        
        # å‹•çš„é‡ã¿ä»˜ã‘
        flc_margin = (flc_loss - flc_threshold) / (flc_threshold * 0.01)
        w_transition = jax.nn.sigmoid(flc_margin * 5.0)
        w_flc = 0.1 + 0.8 * w_transition
        w_bin = 1.0 - w_flc
        
        return w_flc * flc_loss + w_bin * bin_loss, flc_loss, bin_loss
    
    # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶
    optimizer = optax.chain(
        optax.clip_by_global_norm(0.3),
        optax.adamw(learning_rate=1e-3, weight_decay=1e-5)
    )
    
    opt_state = optimizer.init(params_init)
    params = params_init
    
    # å‹¾é…é–¢æ•°
    grad_fn = jax.grad(lambda p: loss_constrained(p)[0])
    
    # å±¥æ­´
    history = {
        'total': [],
        'flc': [],
        'binary': []
    }
    
    # æœ€é©åŒ–ãƒ«ãƒ¼ãƒ—
    for step in range(n_steps):
        # å‹¾é…è¨ˆç®—
        grads = grad_fn(params)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°
        updates, opt_state = optimizer.update(grads, opt_state, params)
        params = optax.apply_updates(params, updates)
        
        # é€²æ—è¡¨ç¤º
        if step % 100 == 0 and verbose:
            total_loss, flc_loss, bin_loss = loss_constrained(params)
            history['total'].append(float(total_loss))
            history['flc'].append(float(flc_loss))
            history['binary'].append(float(bin_loss))
            
            print(f"  Step {step:3d}: Total = {float(total_loss):.6f} "
                  f"(FLC: {float(flc_loss):.6f}, Binary: {float(bin_loss):.6f})")
    
    if verbose:
        print(f"\n  âœ… Phase 1.5Bå®Œäº†ï¼")
    
    return params, history

# =============================================================================
# Section 7: ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =============================================================================

def visualize_safe_manifold(safe_manifold: Dict, output_path: str = None):
    """å®‰å…¨å¤šæ§˜ä½“ã®å¯è¦–åŒ–"""
    import matplotlib.pyplot as plt
    
    lambdas = safe_manifold['lambdas']
    conditions = safe_manifold['conditions']
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # (1) å…¨è»Œé“ãƒ—ãƒ­ãƒƒãƒˆ
    ax = axes[0, 0]
    for i, lam in enumerate(lambdas[:50]):  # æœ€åˆã®50æœ¬
        ax.plot(lam, alpha=0.3, linewidth=0.5)
    ax.set_xlabel('Time Step')
    ax.set_ylabel('Î›(t)')
    ax.set_title(f'Safe Trajectories (n={len(lambdas)})')
    ax.grid(True, alpha=0.3)
    
    # (2) Î²ã”ã¨ã®åˆ†å¸ƒ
    ax = axes[0, 1]
    betas = [c['beta'] for c in conditions]
    peaks = [c['peak_Lambda'] for c in conditions]
    sc = ax.scatter(betas, peaks, c=peaks, cmap='viridis', alpha=0.6)
    ax.set_xlabel('Î² (path ratio)')
    ax.set_ylabel('Peak Î›')
    ax.set_title('Peak Î› vs Î²')
    ax.grid(True, alpha=0.3)
    plt.colorbar(sc, ax=ax, label='Peak Î›')
    
    # (3) Gramè¡Œåˆ—ã®ã‚µãƒ³ãƒ—ãƒ«
    ax = axes[1, 0]
    G_sample = safe_manifold['grams'][0]
    im = ax.imshow(G_sample, cmap='RdBu_r', aspect='auto')
    ax.set_xlabel('Time')
    ax.set_ylabel('Time')
    ax.set_title('Sample Gram Matrix')
    plt.colorbar(im, ax=ax)
    
    # (4) æ¡ä»¶åˆ†å¸ƒ
    ax = axes[1, 1]
    mus = [c['mu'] for c in conditions]
    pNs = [c['pN']/1e6 for c in conditions]  # MPa
    sc = ax.scatter(mus, pNs, c=peaks, cmap='viridis', alpha=0.6)
    ax.set_xlabel('Î¼ (friction)')
    ax.set_ylabel('pN (MPa)')
    ax.set_title('Condition Space Coverage')
    ax.grid(True, alpha=0.3)
    plt.colorbar(sc, ax=ax, label='Peak Î›')
    
    plt.tight_layout()
    
    if output_path:
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"  å¯è¦–åŒ–ä¿å­˜: {output_path}")
    
    plt.show()
    
    return fig

def analyze_safety_scores(
    exps,
    mat_dict,
    edr_dict,
    safe_manifold: Dict,
    simulate_fn,
    weights: Dict[str, float]
):
    """
    å…¨å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã®å®‰å…¨ã‚¹ã‚³ã‚¢åˆ†æ
    """
    from edr_fit_fixed import schedule_to_jax_dict
    
    print("\n" + "="*60)
    print(" ğŸ‚ Safety Score Analysis")
    print("="*60)
    
    safe_grams = safe_manifold['grams']
    
    for i, exp in enumerate(exps):
        schedule_dict = schedule_to_jax_dict(exp.schedule)
        res = simulate_fn(schedule_dict, mat_dict, edr_dict)
        Lambda = res["Lambda"]
        
        # å®‰å…¨ã‚¹ã‚³ã‚¢è¨ˆç®—
        score = float(compute_safety_score(Lambda, safe_grams, weights))
        
        # å„æˆåˆ†ã®å¯„ä¸
        G_test = compute_gram(Lambda)
        distances = [float(gram_distance(G_test, G_safe)) for G_safe in safe_grams]
        min_dist = min(distances)
        
        tv = float(compute_tv(Lambda))
        jump = float(compute_jump_penalty(Lambda))
        topo = float(compute_topo_penalty(Lambda))
        l1 = float(compute_l1_norm(Lambda))
        
        status = "ç ´æ–­" if exp.failed == 1 else "å®‰å…¨"
        
        print(f"\nExp{i} ({exp.label}, {status}):")
        print(f"  Total Score: {score:.4f}")
        print(f"    Gramè·é›¢: {min_dist:.4f}")
        print(f"    TV      : {tv:.4f} (Ã— {weights['tv']:.2f})")
        print(f"    Jump    : {jump:.4f} (Ã— {weights['jump']:.2f})")
        print(f"    Topo    : {topo:.4f} (Ã— {weights['topo']:.2f})")
        print(f"    L1      : {l1:.4f} (Ã— {weights['l1']:.4f})")

# =============================================================================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œä¾‹
# =============================================================================

if __name__ == "__main__":
    print("="*80)
    print(" ğŸ‚ Operation Marie Antoinette")
    print(" ã€Œãƒ‡ãƒ¼ã‚¿ãŒãªã„ãªã‚‰ä½œã‚Œã°ã„ã„ã˜ã‚ƒãªã„ï¼ã€")
    print("="*80)
    
    print("\né€†å•é¡ŒÃ—å¤šæ§˜ä½“å­¦ç¿’ã«ã‚ˆã‚‹ç ´æ–­åˆ¤å®šã‚·ã‚¹ãƒ†ãƒ ")
    print("  - å®‰å…¨å¤šæ§˜ä½“ã®è‡ªå‹•æ§‹ç¯‰")
    print("  - Gramè¡Œåˆ—ãƒ™ãƒ¼ã‚¹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜")
    print("  - ç‰©ç†çš„ç•°å¸¸æ¤œå‡ºï¼ˆTV, Jump, Topoæ­£å‰‡åŒ–ï¼‰")
    print("  - ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆé‹ç”¨å¯èƒ½")
    
    print("\nâœ… ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†")
    print("  edr_fit_fixed.py ã‹ã‚‰ä»¥ä¸‹ã‚’åˆ©ç”¨:")
    print("    - simulate_lambda_jax()")
    print("    - transform_params_jax()")
    print("    - ãã®ä»–ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°")
